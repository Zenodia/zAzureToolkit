{
  "cells": [
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "\nimport azureml.core\nprint(\"SDK version:\", azureml.core.VERSION)",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "SDK version: 1.0.2\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core import Workspace\n#ws=Workspace.get(name='zAML',subscription_id='my_subscription_id')\n",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Create the configuration file.\n#ws.write_config()\n\n# Use this code to load the workspace from \n# other scripts and notebooks in this directory.\n# ws = Workspace.from_config()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core.workspace import Workspace\nws = Workspace.from_config()\nprint('Workspace name: ' + ws.name, \n      'Azure region: ' + ws.location, \n      #'Subscription id: ' + ws.subscription_id, \n      'Resource group: ' + ws.resource_group, sep = '\\n')",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Found the config file in: /home/nbuser/library/aml_config/config.json\nWorkspace name: zAML\nAzure region: westeurope\nResource group: AMLrg\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "\nfrom azureml.core.compute import ComputeTarget, AmlCompute\nfrom azureml.core.compute_target import ComputeTargetException",
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "\nfrom azureml.core import Datastore\n\nds = ws.get_default_datastore()\nprint(\"Using the default datastore for training data: \")\nprint(ds.name, ds.datastore_type, ds.account_name, ds.container_name)",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Using the default datastore for training data: \nworkspaceblobstore AzureBlob zaml5744793264 azureml-blobstore-9d836814-f895-4a65-af78-59f755a38c85\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": " \nfrom azureml.core import Datastore\n# only need to do it once\nds2 = Datastore.register_azure_file_share(workspace=ws, \n                                         datastore_name='CTscands', \n                                         file_share_name='bloodcell',\n                                         account_name='zbatchaistorage', \n                                         account_key='MmkzeKphqtgv83Z3DfieWNF40bdj53FQ7WebO2zPW73Jh3YOxOgGuAkj/gi0Bo/4K+awcWtlGvpDE9tIQvKYYw==',\n                                         create_if_not_exists=False)\n                                         ",
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core.compute import ComputeTarget, AmlCompute\nfrom azureml.core.compute_target import ComputeTargetException\n\n# choose a name for your cluster\ncluster_name = \"gpucluster\"\n\ntry:\n    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n    print('Found existing compute target')\nexcept ComputeTargetException:\n    print('Creating a new compute target...')\n    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_NC6', \n                                                           max_nodes=4)\n\n    # create the cluster\n    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n\n    compute_target.wait_for_completion(show_output=True)\n\n# Use the 'status' property to get a detailed status for the current cluster. \nprint(compute_target.status.serialize())",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Found existing compute target\n{'allocationState': 'Steady', 'allocationStateTransitionTime': '2019-01-09T13:21:06.234000+00:00', 'creationTime': '2019-01-08T10:23:55.033355+00:00', 'currentNodeCount': 0, 'errors': None, 'modifiedTime': '2019-01-08T10:25:35.793472+00:00', 'nodeStateCounts': {'idleNodeCount': 0, 'leavingNodeCount': 0, 'preemptedNodeCount': 0, 'preparingNodeCount': 0, 'runningNodeCount': 0, 'unusableNodeCount': 0}, 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 0, 'maxNodeCount': 4, 'nodeIdleTimeBeforeScaleDown': 'PT120S'}, 'targetNodeCount': 0, 'vmPriority': 'Dedicated', 'vmSize': 'STANDARD_NC6'}\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import os\n\nproject_folder = './keras-ctscan-exp'\nos.makedirs(project_folder, exist_ok=True)",
      "execution_count": 20,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import shutil\n\n#shutil.copy('keras_cnn_dicom.py', project_folder)\nshutil.copy('keras_cnn_pydicom.py', project_folder)\n",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 35,
          "data": {
            "text/plain": "'./keras-ctscan-exp/keras_cnn_pydicom.py'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "cat ./keras-ctscan-exp/keras_cnn_pydicom.py",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": "from __future__ import print_function\r\nimport argparse\r\nimport pydicom\r\nfrom matplotlib import pyplot, cm\r\nimport os\r\nimport sys\r\nimport numpy as np\r\nimport pandas as pd\r\nimport scipy\r\nimport keras\r\nfrom keras.models import Sequential\r\nfrom keras.layers import AveragePooling2D , Convolution2D , Flatten ,Dense, MaxPooling2D, Conv2D\r\nfrom keras.preprocessing import utils\r\nfrom keras.preprocessing.image import ImageDataGenerator\r\n\r\n\r\ndef get_data(dicom_dir):\r\n    #resize the image to desired resolution\r\n    #print(\"dicom_dir\",os.listdir(dicom_dir), dicom_dir)\r\n    xsize = 256; ysize = 256\r\n    \r\n    data = np.zeros((xsize, ysize, 100))\r\n    #print(\"dicom_dir\",os.listdir(dicom_dir), dicom_dir)\r\n    for i, s in enumerate(os.listdir(dicom_dir)):\r\n    \r\n        img = np.array(pydicom.read_file(dicom_dir+ s).pixel_array)\r\n        xscale = xsize/img.shape[0]\r\n        yscale = ysize/img.shape[1]\r\n        data[:,:,i] = scipy.ndimage.interpolation.zoom(img, [xscale, yscale])\r\n    #returning a numpy array of shape 100,256,256\r\n    return data\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nif __name__=='__main__': \r\n    \r\n    parser=argparse.ArgumentParser()\r\n    parser.add_argument('-i','--data',help='directory of where dicom files exists' )\r\n    parser.add_argument('--epoch', help='how many epoch to train on')\r\n    #parser.add_argument('--reload', help='path to where you save the previous model and use it to continue training')\r\n    parser.add_argument('--save_model', help='path to where you want to save the model')\r\n    args=parser.parse_args()\r\n    os.makedirs(args.data,exist_ok=True)\r\n    print(os.path.expandvars(args.data))\r\n    \r\n    X=get_data(args.data+'/ChestCTscan/dicom/')\r\n    X=np.moveaxis(X, -1, 0)\r\n    print(\"check the dicom file shape should be 100, 256,256\", X.shape)\r\n    \r\n    ### get label 1=contrast / 0=no contrast \r\n    df=pd.read_csv(args.data +'/ChestCTscan/overview.csv',encoding='utf-8',sep=',')\r\n    del df['Unnamed: 0']\r\n    y=df.iloc[:,1].values\r\n    y= np.array([1 if yi else 0 for yi in y])\r\n    from sklearn.model_selection import train_test_split\r\n    X_train, X_test, y_train,y_test=train_test_split(X,y , test_size=0.1 , random_state=0)\r\n    ## need to add a fake dimension in the end since keras image_generator expect 4 dim \r\n    X_train=np.expand_dims(X_train, axis=3)\r\n    X_test=np.expand_dims(X_test,axis=3)\r\n    X=np.expand_dims(X,axis=3)\r\n    X_train.shape, X_test.shape , y_train.shape, y_test.shape\r\n    \r\n    train_datagen = ImageDataGenerator(rescale = 1./255,\r\n                                   shear_range = 0.2,\r\n                                   zoom_range = 0.2,\r\n                                   horizontal_flip = True)\r\n\r\n    test_datagen = ImageDataGenerator(rescale = 1./255,\r\n                                   shear_range = 0.2,\r\n                                   zoom_range = 0.2,\r\n                                   horizontal_flip = True)\r\n    train_datagen.fit(X_train, augment=True, seed=123)\r\n    test_datagen.fit(X_test, augment=True, seed=123)\r\n    train_batch=train_datagen.flow(X, y, batch_size=20, seed=123, shuffle=True )\r\n    test_batch=test_datagen.flow(X_test, y_test, batch_size=20, seed=123, shuffle=True )\r\n    # Initialising the CNN\r\n    classifier = Sequential()\r\n    \r\n    # Step 1 - Convolution\r\n    classifier.add(Conv2D(32, (3, 3), input_shape = (256, 256 ,1), activation = 'relu', padding=\"same\"))\r\n    \r\n    # Step 2 - Pooling\r\n    classifier.add(MaxPooling2D(pool_size = (2, 2)))\r\n    \r\n    # Adding a second convolutional layer\r\n    classifier.add(Conv2D(64, 3, 3, activation = 'relu'))\r\n    classifier.add(MaxPooling2D(pool_size = (2, 2)))\r\n    \r\n    # Adding a second convolutional layer\r\n    classifier.add(Conv2D(128, 3, 3, activation = 'relu'))\r\n    classifier.add(MaxPooling2D(pool_size = (2, 2)))\r\n    \r\n        \r\n    # Adding a second convolutional layer\r\n    classifier.add(Conv2D(256, 3, 3, activation = 'relu'))\r\n    classifier.add(MaxPooling2D(pool_size = (2, 2)))\r\n    \r\n    # Step 3 - Flattening\r\n    classifier.add(Flatten())\r\n    \r\n    # Step 4 - Full connection\r\n    classifier.add(Dense(units = 128, activation = 'relu')) # the output_dim is chosen by experience\r\n    classifier.add(Dense(units = 1, activation = 'sigmoid'))\r\n    \r\n    # Compiling the CNN\r\n    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\r\n    \r\n    classifier.fit_generator(train_batch,\r\n                             steps_per_epoch = 100,\r\n                             nb_epoch = int(args.epoch),\r\n                             validation_data = test_batch,\r\n                             validation_steps = 25)\r\n    from keras.models import load_model\r\n    os.makedirs(args.save_model,exist_ok=True)\r\n    # Creates a HDF5 file 'my_model.h5'\r\n    classifier.save(args.save_model+'/ChestCTscan_epoch{}.h5'.format(args.epoch))\r\n    \r\n    \r\n    # Returns a compiled model identical to the previous one\r\n    #model = load_model(save_model+'ChestCTscan.h5')\r\n    \r\n\r\n    \r\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core import Experiment\n\nexperiment_name = 'keras-tf-exp'\nexperiment = Experiment(ws, name=experiment_name)",
      "execution_count": 37,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "\nds2.path()",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/plain": "$AZUREML_DATAREFERENCE_ctscands"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.train.dnn import TensorFlow \nscript_params={\n    '--data': ds2.path(),\n    '--epoch': 1,\n    '--save_model':'/outputs'\n}\n\nestimator = TensorFlow(source_directory=project_folder,\n                      compute_target=compute_target,\n                      entry_script='keras_cnn_pydicom.py',\n                      script_params=script_params,\n                      node_count=1,\n                      process_count_per_node=1,\n                      #distributed_backend='mpi',    \n                      pip_packages=['pydicom','keras','scikit-image','scikit-learn','scipy','argparse',\n                                    'opencv-contrib-python-headless','pillow','numpy', 'pandas','matplotlib'],\n                      #custom_docker_base_image='zecharpy/tfgpupy3:pydicom',\n                      use_gpu=True)",
      "execution_count": 38,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "run = experiment.submit(estimator)\nprint(run)",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Run(Experiment: keras-tf-exp,\nId: keras-tf-exp_1547042123229,\nType: azureml.scriptrun,\nStatus: Queued)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.widgets import RunDetails\nRunDetails(run).show()",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "16e639ab49b34abf8dcc81f4eb10c791",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'NOTSET',â€¦"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "run.wait_for_completion(show_output=True)",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": "RunId: keras-tf-exp_1547042123229\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "MSI: Failed to retrieve a token from 'http://localhost:25198/nb/api/nbsvc/oauth2/token' with an error of 'HTTPConnectionPool(host='localhost', port=25198): Max retries exceeded with url: /nb/api/nbsvc/oauth2/token (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f9e5c36bf60>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution',))'. This could be caused by the MSI extension not yet fullly provisioned.\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "\nStreaming azureml-logs/60_control_log.txt\n=========================================\n\nStreaming log file azureml-logs/60_control_log.txt\n\nStreaming azureml-logs/80_driver_log.txt\n========================================\n\nUsing TensorFlow backend.\n/mnt/batch/tasks/shared/LS_root/jobs/zaml/azureml/keras-tf-exp_1547042123229/mounts/ctscands\ncheck the dicom file shape should be 100, 256,256 (100, 256, 256)\nkeras_cnn_pydicom.py:92: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n  classifier.add(Conv2D(64, 3, 3, activation = 'relu'))\nkeras_cnn_pydicom.py:96: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\")`\n  classifier.add(Conv2D(128, 3, 3, activation = 'relu'))\nkeras_cnn_pydicom.py:101: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\")`\n  classifier.add(Conv2D(256, 3, 3, activation = 'relu'))\nkeras_cnn_pydicom.py:118: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n  validation_steps = 25)\nkeras_cnn_pydicom.py:118: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., steps_per_epoch=100, validation_data=<keras_pre..., validation_steps=25, epochs=1)`\n  validation_steps = 25)\nEpoch 1/1\n2019-01-09 14:06:58.567149: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n2019-01-09 14:06:58.679482: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 0 with properties: \nname: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\npciBusID: 5d6f:00:00.0\ntotalMemory: 11.17GiB freeMemory: 11.10GiB\n2019-01-09 14:06:58.679524: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 0\n2019-01-09 14:06:58.953786: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:\n2019-01-09 14:06:58.953843: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      0 \n2019-01-09 14:06:58.953855: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 0:   N \n2019-01-09 14:06:58.954110: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10758 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 5d6f:00:00.0, compute capability: 3.7)\n\n  1/100 [..............................] - ETA: 4:39 - loss: 0.6972 - acc: 0.5500\n  2/100 [..............................] - ETA: 2:23 - loss: 1.9243 - acc: 0.5000\n  3/100 [..............................] - ETA: 1:37 - loss: 1.6741 - acc: 0.4667\n  4/100 [>.............................] - ETA: 1:14 - loss: 1.4263 - acc: 0.5000\n  5/100 [>.............................] - ETA: 1:00 - loss: 1.2767 - acc: 0.5100\n  6/100 [>.............................] - ETA: 53s - loss: 1.1811 - acc: 0.5000 \n  7/100 [=>............................] - ETA: 46s - loss: 1.1109 - acc: 0.5143\n  8/100 [=>............................] - ETA: 41s - loss: 1.0575 - acc: 0.5188\n  9/100 [=>............................] - ETA: 37s - loss: 1.0162 - acc: 0.5167\n 10/100 [==>...........................] - ETA: 33s - loss: 0.9854 - acc: 0.5050\n 11/100 [==>...........................] - ETA: 31s - loss: 0.9579 - acc: 0.5136\n 12/100 [==>...........................] - ETA: 29s - loss: 0.9331 - acc: 0.5292\n 13/100 [==>...........................] - ETA: 27s - loss: 0.9134 - acc: 0.5385\n 14/100 [===>..........................] - ETA: 25s - loss: 0.8969 - acc: 0.5357\n 15/100 [===>..........................] - ETA: 24s - loss: 0.8789 - acc: 0.5500\n 16/100 [===>..........................] - ETA: 23s - loss: 0.8662 - acc: 0.5531\n 17/100 [====>.........................] - ETA: 21s - loss: 0.8497 - acc: 0.5618\n 18/100 [====>.........................] - ETA: 20s - loss: 0.8397 - acc: 0.5750\n 19/100 [====>.........................] - ETA: 19s - loss: 0.8305 - acc: 0.5737\n 20/100 [=====>........................] - ETA: 19s - loss: 0.8210 - acc: 0.5800\n 21/100 [=====>........................] - ETA: 18s - loss: 0.8094 - acc: 0.5881\n 22/100 [=====>........................] - ETA: 17s - loss: 0.7943 - acc: 0.6045\n 23/100 [=====>........................] - ETA: 17s - loss: 0.7899 - acc: 0.6109\n 24/100 [======>.......................] - ETA: 16s - loss: 0.7824 - acc: 0.6146\n 25/100 [======>.......................] - ETA: 15s - loss: 0.7815 - acc: 0.6120\n 26/100 [======>.......................] - ETA: 15s - loss: 0.7730 - acc: 0.6173\n 27/100 [=======>......................] - ETA: 14s - loss: 0.7662 - acc: 0.6185\n 28/100 [=======>......................] - ETA: 14s - loss: 0.7595 - acc: 0.6250\n 29/100 [=======>......................] - ETA: 13s - loss: 0.7549 - acc: 0.6276\n 30/100 [========>.....................] - ETA: 13s - loss: 0.7503 - acc: 0.6317\n 31/100 [========>.....................] - ETA: 13s - loss: 0.7415 - acc: 0.6387\n 32/100 [========>.....................] - ETA: 12s - loss: 0.7350 - acc: 0.6391\n 33/100 [========>.....................] - ETA: 12s - loss: 0.7304 - acc: 0.6409\n 34/100 [=========>....................] - ETA: 12s - loss: 0.7265 - acc: 0.6426\n 35/100 [=========>....................] - ETA: 11s - loss: 0.7224 - acc: 0.6429\n 36/100 [=========>....................] - ETA: 11s - loss: 0.7144 - acc: 0.6486\n 37/100 [==========>...................] - ETA: 11s - loss: 0.7119 - acc: 0.6514\n 38/100 [==========>...................] - ETA: 10s - loss: 0.7126 - acc: 0.6447\n 39/100 [==========>...................] - ETA: 10s - loss: 0.7076 - acc: 0.6474\n 40/100 [===========>..................] - ETA: 10s - loss: 0.7036 - acc: 0.6513\n 41/100 [===========>..................] - ETA: 9s - loss: 0.7001 - acc: 0.6537 \n 42/100 [===========>..................] - ETA: 9s - loss: 0.6928 - acc: 0.6571\n 43/100 [===========>..................] - ETA: 9s - loss: 0.6893 - acc: 0.6570\n 44/100 [============>.................] - ETA: 9s - loss: 0.6853 - acc: 0.6614\n 45/100 [============>.................] - ETA: 8s - loss: 0.6786 - acc: 0.6667\n 46/100 [============>.................] - ETA: 8s - loss: 0.6725 - acc: 0.6717\n 47/100 [=============>................] - ETA: 8s - loss: 0.6734 - acc: 0.6734\n 48/100 [=============>................] - ETA: 8s - loss: 0.6652 - acc: 0.6792\n 49/100 [=============>................] - ETA: 8s - loss: 0.6613 - acc: 0.6816\n 50/100 [==============>...............] - ETA: 7s - loss: 0.6662 - acc: 0.6780\n 51/100 [==============>...............] - ETA: 7s - loss: 0.6633 - acc: 0.6794\n 52/100 [==============>...............] - ETA: 7s - loss: 0.6584 - acc: 0.6808\n 53/100 [==============>...............] - ETA: 7s - loss: 0.6532 - acc: 0.6821\n 54/100 [===============>..............] - ETA: 6s - loss: 0.6518 - acc: 0.6815\n 55/100 [===============>..............] - ETA: 6s - loss: 0.6489 - acc: 0.6809\n 56/100 [===============>..............] - ETA: 6s - loss: 0.6473 - acc: 0.6812\n 57/100 [================>.............] - ETA: 6s - loss: 0.6425 - acc: 0.6851\n 58/100 [================>.............] - ETA: 6s - loss: 0.6396 - acc: 0.6862\n 59/100 [================>.............] - ETA: 6s - loss: 0.6349 - acc: 0.6890\n 60/100 [=================>............] - ETA: 5s - loss: 0.6306 - acc: 0.6900\n 61/100 [=================>............] - ETA: 5s - loss: 0.6266 - acc: 0.6918\n 62/100 [=================>............] - ETA: 5s - loss: 0.6218 - acc: 0.6952\n 63/100 [=================>............] - ETA: 5s - loss: 0.6190 - acc: 0.6952\n 64/100 [==================>...........] - ETA: 5s - loss: 0.6226 - acc: 0.6945\n 65/100 [==================>...........] - ETA: 5s - loss: 0.6185 - acc: 0.6969\n 66/100 [==================>...........] - ETA: 4s - loss: 0.6205 - acc: 0.6955\n 67/100 [===================>..........] - ETA: 4s - loss: 0.6146 - acc: 0.6993\n 68/100 [===================>..........] - ETA: 4s - loss: 0.6136 - acc: 0.6993\n 69/100 [===================>..........] - ETA: 4s - loss: 0.6136 - acc: 0.6986\n 70/100 [====================>.........] - ETA: 4s - loss: 0.6103 - acc: 0.7007\n 71/100 [====================>.........] - ETA: 4s - loss: 0.6076 - acc: 0.7021\n 72/100 [====================>.........] - ETA: 3s - loss: 0.6027 - acc: 0.7056\n 73/100 [====================>.........] - ETA: 3s - loss: 0.5998 - acc: 0.7082\n 74/100 [=====================>........] - ETA: 3s - loss: 0.5967 - acc: 0.7095\n 75/100 [=====================>........] - ETA: 3s - loss: 0.5955 - acc: 0.7080\n 76/100 [=====================>........] - ETA: 3s - loss: 0.5930 - acc: 0.7099\n 77/100 [======================>.......] - ETA: 3s - loss: 0.5903 - acc: 0.7123\n 78/100 [======================>.......] - ETA: 3s - loss: 0.5860 - acc: 0.7141\n 79/100 [======================>.......] - ETA: 2s - loss: 0.5849 - acc: 0.7146\n 80/100 [=======================>......] - ETA: 2s - loss: 0.5850 - acc: 0.7144\n 81/100 [=======================>......] - ETA: 2s - loss: 0.5816 - acc: 0.7167\n 82/100 [=======================>......] - ETA: 2s - loss: 0.5786 - acc: 0.7177\n 83/100 [=======================>......] - ETA: 2s - loss: 0.5762 - acc: 0.7181\n 84/100 [========================>.....] - ETA: 2s - loss: 0.5716 - acc: 0.7202\n 85/100 [========================>.....] - ETA: 2s - loss: 0.5693 - acc: 0.7206\n 86/100 [========================>.....] - ETA: 1s - loss: 0.5657 - acc: 0.7221\n 87/100 [=========================>....] - ETA: 1s - loss: 0.5631 - acc: 0.7236\n 88/100 [=========================>....] - ETA: 1s - loss: 0.5593 - acc: 0.7256\n 89/100 [=========================>....] - ETA: 1s - loss: 0.5569 - acc: 0.7264\n 90/100 [==========================>...] - ETA: 1s - loss: 0.5548 - acc: 0.7283\n 91/100 [==========================>...] - ETA: 1s - loss: 0.5517 - acc: 0.7302\n 92/100 [==========================>...] - ETA: 1s - loss: 0.5487 - acc: 0.7315\n 93/100 [==========================>...] - ETA: 0s - loss: 0.5474 - acc: 0.7317\n 94/100 [===========================>..] - ETA: 0s - loss: 0.5436 - acc: 0.7340\n 95/100 [===========================>..] - ETA: 0s - loss: 0.5412 - acc: 0.7358\n 96/100 [===========================>..] - ETA: 0s - loss: 0.5378 - acc: 0.7380\n 97/100 [============================>.] - ETA: 0s - loss: 0.5338 - acc: 0.7402\n 98/100 [============================>.] - ETA: 0s - loss: 0.5310 - acc: 0.7418\n 99/100 [============================>.] - ETA: 0s - loss: 0.5276 - acc: 0.7434\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "100/100 [==============================] - 16s 156ms/step - loss: 0.5244 - acc: 0.7450 - val_loss: 0.0991 - val_acc: 0.9880\n\n\nThe experiment completed successfully. Finalizing run...\nLogging experiment finalizing status in history service\nCleaning up all outstanding Run operations, waiting 300.0 seconds\n1 items cleaning up...\nCleanup took 0.10054397583007812 seconds\n\nExecution Summary\n=================\nRunId: keras-tf-exp_1547042123229\n\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 41,
          "data": {
            "text/plain": "{'runId': 'keras-tf-exp_1547042123229',\n 'target': 'gpucluster',\n 'status': 'Finalizing',\n 'startTimeUtc': '2019-01-09T14:02:42.167711Z',\n 'properties': {'azureml.runsource': 'experiment',\n  'ContentSnapshotId': '5839616d-bfcb-4ebb-8d2e-48b0332ce548'},\n 'runDefinition': {'Script': 'keras_cnn_pydicom.py',\n  'Arguments': ['--data',\n   '$AZUREML_DATAREFERENCE_ctscands',\n   '--epoch',\n   '1',\n   '--save_model',\n   '/outputs'],\n  'SourceDirectoryDataStore': None,\n  'Framework': 0,\n  'Communicator': 0,\n  'Target': 'gpucluster',\n  'DataReferences': {'ctscands': {'DataStoreName': 'ctscands',\n    'Mode': 'Mount',\n    'PathOnDataStore': None,\n    'PathOnCompute': None,\n    'Overwrite': False}},\n  'JobName': None,\n  'AutoPrepareEnvironment': True,\n  'MaxRunDurationSeconds': None,\n  'NodeCount': 1,\n  'Environment': {'Python': {'InterpreterPath': 'python',\n    'UserManagedDependencies': False,\n    'CondaDependencies': {'name': 'project_environment',\n     'dependencies': ['python=3.6.2',\n      {'pip': ['azureml-defaults',\n        'tensorflow-gpu==1.10.0',\n        'pydicom',\n        'keras',\n        'scikit-image',\n        'scikit-learn',\n        'scipy',\n        'argparse',\n        'opencv-contrib-python-headless',\n        'pillow',\n        'numpy',\n        'pandas',\n        'matplotlib']}]},\n    'CondaDependenciesFile': None},\n   'EnvironmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE',\n    'NCCL_SOCKET_IFNAME': '^docker0'},\n   'Docker': {'BaseImage': 'mcr.microsoft.com/azureml/base-gpu:0.2.0',\n    'Enabled': True,\n    'SharedVolumes': True,\n    'Preparation': None,\n    'GpuSupport': True,\n    'Arguments': [],\n    'BaseImageRegistry': {'Address': None,\n     'Username': None,\n     'Password': None}},\n   'Spark': {'Repositories': ['https://mmlspark.azureedge.net/maven'],\n    'Packages': [{'Group': 'com.microsoft.ml.spark',\n      'Artifact': 'mmlspark_2.11',\n      'Version': '0.12'}],\n    'PrecachePackages': True}},\n  'History': {'OutputCollection': True},\n  'Spark': {'Configuration': {'spark.app.name': 'Azure ML Experiment',\n    'spark.yarn.maxAppAttempts': '1'}},\n  'BatchAi': {'NodeCount': 0},\n  'AmlCompute': {'Name': None,\n   'VmSize': None,\n   'VmPriority': None,\n   'RetainCluster': False,\n   'ClusterMaxNodeCount': 1},\n  'Tensorflow': {'WorkerCount': 1, 'ParameterServerCount': 1},\n  'Mpi': {'ProcessCountPerNode': 1},\n  'Hdi': {'YarnDeployMode': 2},\n  'ContainerInstance': {'Region': None, 'CpuCores': 0, 'MemoryGb': 0},\n  'ExposedPorts': None,\n  'PrepareEnvironment': None},\n 'logFiles': {'azureml-logs/60_control_log.txt': 'https://zaml5744793264.blob.core.windows.net/azureml/ExperimentRun/keras-tf-exp_1547042123229/azureml-logs/60_control_log.txt?sv=2018-03-28&sr=b&sig=6CcRuKYWlY4S7JAAH6MGEczcrEwus13EV0lxsQw4fak%3D&st=2019-01-09T13%3A57%3A17Z&se=2019-01-09T22%3A07%3A17Z&sp=r',\n  'azureml-logs/80_driver_log.txt': 'https://zaml5744793264.blob.core.windows.net/azureml/ExperimentRun/keras-tf-exp_1547042123229/azureml-logs/80_driver_log.txt?sv=2018-03-28&sr=b&sig=Xd8pNT%2FevPExwkWfClblP73k2RLgmZIx24g8eHo3SbE%3D&st=2019-01-09T13%3A57%3A17Z&se=2019-01-09T22%3A07%3A17Z&sp=r',\n  'azureml-logs/azureml.log': 'https://zaml5744793264.blob.core.windows.net/azureml/ExperimentRun/keras-tf-exp_1547042123229/azureml-logs/azureml.log?sv=2018-03-28&sr=b&sig=lUzWTdJudPqI9ySNYJG6c2VSvmi7gjU1lcarjdDT9yk%3D&st=2019-01-09T13%3A57%3A17Z&se=2019-01-09T22%3A07%3A17Z&sp=r'}}"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}