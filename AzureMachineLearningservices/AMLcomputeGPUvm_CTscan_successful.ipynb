{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 1.0.10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import azureml.core\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "#ws=Workspace.get(name='zAML',subscription_id='my_subscription_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the configuration file.\n",
    "#ws.write_config()\n",
    "\n",
    "# Use this code to load the workspace from \n",
    "# other scripts and notebooks in this directory.\n",
    "# ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the config file in: /home/nbuser/library/aml_config/config.json\n",
      "Workspace name: zAML\n",
      "Azure region: westeurope\n",
      "Resource group: AMLrg\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.workspace import Workspace\n",
    "ws = Workspace.from_config()\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      #'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the default datastore for training data: \n",
      "workspaceblobstore AzureBlob zaml5744793264 azureml-blobstore-9d836814-f895-4a65-af78-59f755a38c85\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from azureml.core import Datastore\n",
    "\n",
    "ds = ws.get_default_datastore()\n",
    "print(\"Using the default datastore for training data: \")\n",
    "print(ds.name, ds.datastore_type, ds.account_name, ds.container_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "from azureml.core import Datastore\n",
    "# only need to do it once\n",
    "ds2 = Datastore.register_azure_file_share(workspace=ws, \n",
    "                                         datastore_name='give_a_name_of_your_choice', \n",
    "                                         file_share_name='file_share_name',\n",
    "                                         account_name='your_storage_acc_name', \n",
    "                                         account_key='your_storage_acc_key',\n",
    "                                         create_if_not_exists=False)\n",
    "                                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing compute target\n",
      "{'allocationState': 'Steady', 'allocationStateTransitionTime': '2019-02-28T13:46:20.126000+00:00', 'creationTime': '2019-01-08T10:23:55.033355+00:00', 'currentNodeCount': 0, 'errors': None, 'modifiedTime': '2019-01-08T10:25:35.793472+00:00', 'nodeStateCounts': {'idleNodeCount': 0, 'leavingNodeCount': 0, 'preemptedNodeCount': 0, 'preparingNodeCount': 0, 'runningNodeCount': 0, 'unusableNodeCount': 0}, 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 0, 'maxNodeCount': 4, 'nodeIdleTimeBeforeScaleDown': 'PT120S'}, 'targetNodeCount': 0, 'vmPriority': 'Dedicated', 'vmSize': 'STANDARD_NC6'}\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# choose a name for your cluster\n",
    "cluster_name = \"gpucluster\"\n",
    "\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing compute target')\n",
    "except ComputeTargetException:\n",
    "    print('Creating a new compute target...')\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_NC6', \n",
    "                                                           max_nodes=4)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "    compute_target.wait_for_completion(show_output=True)\n",
    "\n",
    "# Use the 'status' property to get a detailed status for the current cluster. \n",
    "print(compute_target.status.serialize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "project_folder = './keras-ctscan-exp-feb28'\n",
    "os.makedirs(project_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./keras-ctscan-exp-feb28/keras_cnn_pydicom.py'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "#shutil.copy('keras_cnn_dicom.py', project_folder)\n",
    "shutil.copy('keras_cnn_pydicom.py', project_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from __future__ import print_function\r\n",
      "import argparse\r\n",
      "import pydicom\r\n",
      "from matplotlib import pyplot, cm\r\n",
      "import os\r\n",
      "import sys\r\n",
      "import numpy as np\r\n",
      "import pandas as pd\r\n",
      "import scipy\r\n",
      "import keras\r\n",
      "from keras.models import Sequential\r\n",
      "from keras.layers import AveragePooling2D , Convolution2D , Flatten ,Dense, MaxPooling2D, Conv2D\r\n",
      "from keras.preprocessing import utils\r\n",
      "from keras.preprocessing.image import ImageDataGenerator\r\n",
      "\r\n",
      "\r\n",
      "def get_data(dicom_dir):\r\n",
      "    #resize the image to desired resolution\r\n",
      "    #print(\"dicom_dir\",os.listdir(dicom_dir), dicom_dir)\r\n",
      "    xsize = 256; ysize = 256\r\n",
      "    \r\n",
      "    data = np.zeros((xsize, ysize, 100))\r\n",
      "    #print(\"dicom_dir\",os.listdir(dicom_dir), dicom_dir)\r\n",
      "    for i, s in enumerate(os.listdir(dicom_dir)):\r\n",
      "    \r\n",
      "        img = np.array(pydicom.read_file(dicom_dir+ s).pixel_array)\r\n",
      "        xscale = xsize/img.shape[0]\r\n",
      "        yscale = ysize/img.shape[1]\r\n",
      "        data[:,:,i] = scipy.ndimage.interpolation.zoom(img, [xscale, yscale])\r\n",
      "    #returning a numpy array of shape 100,256,256\r\n",
      "    return data\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "if __name__=='__main__': \r\n",
      "    \r\n",
      "    parser=argparse.ArgumentParser()\r\n",
      "    parser.add_argument('-i','--data',help='directory of where dicom files exists' )\r\n",
      "    parser.add_argument('--epoch', help='how many epoch to train on')\r\n",
      "    #parser.add_argument('--reload', help='path to where you save the previous model and use it to continue training')\r\n",
      "    parser.add_argument('--save_model', help='path to where you want to save the model')\r\n",
      "    args=parser.parse_args()\r\n",
      "    os.makedirs(args.data,exist_ok=True)\r\n",
      "    print(os.path.expandvars(args.data))\r\n",
      "    \r\n",
      "    X=get_data(args.data+'/ChestCTscan/dicom/')\r\n",
      "    X=np.moveaxis(X, -1, 0)\r\n",
      "    print(\"check the dicom file shape should be 100, 256,256\", X.shape)\r\n",
      "    \r\n",
      "    ### get label 1=contrast / 0=no contrast \r\n",
      "    df=pd.read_csv(args.data +'/ChestCTscan/overview.csv',encoding='utf-8',sep=',')\r\n",
      "    del df['Unnamed: 0']\r\n",
      "    y=df.iloc[:,1].values\r\n",
      "    y= np.array([1 if yi else 0 for yi in y])\r\n",
      "    from sklearn.model_selection import train_test_split\r\n",
      "    X_train, X_test, y_train,y_test=train_test_split(X,y , test_size=0.1 , random_state=0)\r\n",
      "    ## need to add a fake dimension in the end since keras image_generator expect 4 dim \r\n",
      "    X_train=np.expand_dims(X_train, axis=3)\r\n",
      "    X_test=np.expand_dims(X_test,axis=3)\r\n",
      "    X=np.expand_dims(X,axis=3)\r\n",
      "    X_train.shape, X_test.shape , y_train.shape, y_test.shape\r\n",
      "    \r\n",
      "    train_datagen = ImageDataGenerator(rescale = 1./255,\r\n",
      "                                   shear_range = 0.2,\r\n",
      "                                   zoom_range = 0.2,\r\n",
      "                                   horizontal_flip = True)\r\n",
      "\r\n",
      "    test_datagen = ImageDataGenerator(rescale = 1./255,\r\n",
      "                                   shear_range = 0.2,\r\n",
      "                                   zoom_range = 0.2,\r\n",
      "                                   horizontal_flip = True)\r\n",
      "    train_datagen.fit(X_train, augment=True, seed=123)\r\n",
      "    test_datagen.fit(X_test, augment=True, seed=123)\r\n",
      "    train_batch=train_datagen.flow(X, y, batch_size=20, seed=123, shuffle=True )\r\n",
      "    test_batch=test_datagen.flow(X_test, y_test, batch_size=20, seed=123, shuffle=True )\r\n",
      "    # Initialising the CNN\r\n",
      "    classifier = Sequential()\r\n",
      "    \r\n",
      "    # Step 1 - Convolution\r\n",
      "    classifier.add(Conv2D(32, (3, 3), input_shape = (256, 256 ,1), activation = 'relu', padding=\"same\"))\r\n",
      "    \r\n",
      "    # Step 2 - Pooling\r\n",
      "    classifier.add(MaxPooling2D(pool_size = (2, 2)))\r\n",
      "    \r\n",
      "    # Adding a second convolutional layer\r\n",
      "    classifier.add(Conv2D(64, 3, 3, activation = 'relu'))\r\n",
      "    classifier.add(MaxPooling2D(pool_size = (2, 2)))\r\n",
      "    \r\n",
      "    # Adding a second convolutional layer\r\n",
      "    classifier.add(Conv2D(128, 3, 3, activation = 'relu'))\r\n",
      "    classifier.add(MaxPooling2D(pool_size = (2, 2)))\r\n",
      "    \r\n",
      "        \r\n",
      "    # Adding a second convolutional layer\r\n",
      "    classifier.add(Conv2D(256, 3, 3, activation = 'relu'))\r\n",
      "    classifier.add(MaxPooling2D(pool_size = (2, 2)))\r\n",
      "    \r\n",
      "    # Step 3 - Flattening\r\n",
      "    classifier.add(Flatten())\r\n",
      "    \r\n",
      "    # Step 4 - Full connection\r\n",
      "    classifier.add(Dense(units = 128, activation = 'relu')) # the output_dim is chosen by experience\r\n",
      "    classifier.add(Dense(units = 1, activation = 'sigmoid'))\r\n",
      "    \r\n",
      "    # Compiling the CNN\r\n",
      "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\r\n",
      "    \r\n",
      "    classifier.fit_generator(train_batch,\r\n",
      "                             steps_per_epoch = 100,\r\n",
      "                             nb_epoch = int(args.epoch),\r\n",
      "                             validation_data = test_batch,\r\n",
      "                             validation_steps = 25)\r\n",
      "    from keras.models import load_model\r\n",
      "    os.makedirs(args.save_model,exist_ok=True)\r\n",
      "    # Creates a HDF5 file 'my_model.h5'\r\n",
      "    classifier.save(args.save_model+'/ChestCTscan_epoch{}.h5'.format(args.epoch))\r\n",
      "    \r\n",
      "    \r\n",
      "    # Returns a compiled model identical to the previous one\r\n",
      "    #model = load_model(save_model+'ChestCTscan.h5')\r\n",
      "    \r\n",
      "\r\n",
      "    \r\n"
     ]
    }
   ],
   "source": [
    "cat ./keras-ctscan-exp-feb28/keras_cnn_pydicom.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "experiment_name = 'keras-tf-exp-feb28'\n",
    "experiment = Experiment(ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_ctscands"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ds2.path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.dnn import TensorFlow \n",
    "script_params={\n",
    "    '--data': ds2.path(),\n",
    "    '--epoch': 1,\n",
    "    '--save_model':'/outputs'\n",
    "}\n",
    "\n",
    "estimator = TensorFlow(source_directory=project_folder,\n",
    "                      compute_target=compute_target,\n",
    "                      entry_script='keras_cnn_pydicom.py',\n",
    "                      script_params=script_params,\n",
    "                      node_count=1,\n",
    "                      process_count_per_node=1,\n",
    "                      #distributed_backend='mpi',    \n",
    "                      pip_packages=['pydicom','keras','scikit-image','scikit-learn','scipy','argparse',\n",
    "                                    'opencv-contrib-python-headless','pillow','numpy==1.14.5', 'pandas','matplotlib'],\n",
    "                      #custom_docker_base_image='zecharpy/tfgpupy3:pydicom',\n",
    "                      use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(Experiment: keras-tf-exp-feb28,\n",
      "Id: keras-tf-exp-feb28_1551369917_43572d77,\n",
      "Type: azureml.scriptrun,\n",
      "Status: Starting)\n"
     ]
    }
   ],
   "source": [
    "run = experiment.submit(estimator)\n",
    "print(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "557d1f449a5c4a4bbabba0be28969f12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: keras-tf-exp-feb28_1551369917_43572d77\n",
      "\n",
      "Streaming azureml-logs/20_image_build_log.txt\n",
      "=============================================\n",
      "\n",
      "2019/02/28 16:05:40 Using acb_vol_a95ff98d-830e-483d-be27-1fa648e114e8 as the home volume\n",
      "2019/02/28 16:05:40 Creating Docker network: acb_default_network, driver: 'bridge'\n",
      "2019/02/28 16:05:41 Successfully set up Docker network: acb_default_network\n",
      "2019/02/28 16:05:41 Setting up Docker configuration...\n",
      "2019/02/28 16:05:43 Successfully set up Docker configuration\n",
      "2019/02/28 16:05:43 Logging in to registry: zaml3818199666.azurecr.io\n",
      "2019/02/28 16:05:47 Successfully logged into zaml3818199666.azurecr.io\n",
      "2019/02/28 16:05:47 Executing step ID: acb_step_0. Working directory: '', Network: 'acb_default_network'\n",
      "2019/02/28 16:05:47 Obtaining source code and scanning for dependencies...\n",
      "2019/02/28 16:05:48 Successfully obtained source code and scanned for dependencies\n",
      "2019/02/28 16:05:48 Launching container with name: acb_step_0\n",
      "Sending build context to Docker daemon  40.96kB\n",
      "\n",
      "Step 1/13 : FROM mcr.microsoft.com/azureml/base-gpu:0.2.1\n",
      "0.2.1: Pulling from azureml/base-gpu\n",
      "7b722c1070cd: Already exists\n",
      "5fbf74db61f1: Already exists\n",
      "ed41cb72e5c9: Already exists\n",
      "7ea47a67709e: Already exists\n",
      "e986a5da9812: Pulling fs layer\n",
      "fcf92330fc84: Pulling fs layer\n",
      "93f701a1b3a0: Pulling fs layer\n",
      "52ab5449a7fb: Pulling fs layer\n",
      "ad2cbdb1079e: Pulling fs layer\n",
      "df677fc43fdf: Pulling fs layer\n",
      "220ea4374d17: Pulling fs layer\n",
      "52ab5449a7fb: Waiting\n",
      "ad2cbdb1079e: Waiting\n",
      "df677fc43fdf: Waiting\n",
      "220ea4374d17: Waiting\n",
      "e986a5da9812: Verifying Checksum\n",
      "e986a5da9812: Download complete\n",
      "e986a5da9812: Pull complete\n",
      "52ab5449a7fb: Verifying Checksum\n",
      "52ab5449a7fb: Download complete\n",
      "ad2cbdb1079e: Download complete\n",
      "fcf92330fc84: Verifying Checksum\n",
      "fcf92330fc84: Download complete\n",
      "df677fc43fdf: Verifying Checksum\n",
      "df677fc43fdf: Download complete\n",
      "93f701a1b3a0: Verifying Checksum\n",
      "93f701a1b3a0: Download complete\n",
      "fcf92330fc84: Pull complete\n",
      "93f701a1b3a0: Pull complete\n",
      "220ea4374d17: Verifying Checksum\n",
      "220ea4374d17: Download complete\n",
      "52ab5449a7fb: Pull complete\n",
      "ad2cbdb1079e: Pull complete\n",
      "df677fc43fdf: Pull complete\n",
      "220ea4374d17: Pull complete\n",
      "Digest: sha256:eb26cf5e4a6852a3b9029299ee17424b31f458b293066c11824135530617a073\n",
      "Status: Downloaded newer image for mcr.microsoft.com/azureml/base-gpu:0.2.1\n",
      " ---> b1d15c3ed71e\n",
      "Step 2/13 : USER root\n",
      " ---> Running in fd29188872d6\n",
      "Removing intermediate container fd29188872d6\n",
      " ---> 1a9ea6857f7f\n",
      "Step 3/13 : RUN mkdir -p $HOME/.cache\n",
      " ---> Running in 07fb0608dbb5\n",
      "Removing intermediate container 07fb0608dbb5\n",
      " ---> 41875985a57e\n",
      "Step 4/13 : WORKDIR /\n",
      " ---> Running in c902c93a5290\n",
      "Removing intermediate container c902c93a5290\n",
      " ---> 70ef579af049\n",
      "Step 5/13 : COPY azureml-setup/99brokenproxy /etc/apt/apt.conf.d/\n",
      " ---> 7182d3b27799\n",
      "Step 6/13 : RUN if dpkg --compare-versions `conda --version | grep -oE '[^ ]+$'` lt 4.4.0; then conda install conda==4.4.11; fi\n",
      " ---> Running in e99511d843a7\n",
      "Removing intermediate container e99511d843a7\n",
      " ---> 1e43aea44aca\n",
      "Step 7/13 : COPY azureml-setup/mutated_conda_dependencies.yml azureml-setup/mutated_conda_dependencies.yml\n",
      " ---> 943ab83c94db\n",
      "Step 8/13 : RUN ldconfig /usr/local/cuda/lib64/stubs && conda env create -p /azureml-envs/azureml_d0a02ed84b7b88651f66388ea6efaa54 -f azureml-setup/mutated_conda_dependencies.yml && ldconfig\n",
      " ---> Running in ec1de67c562d\n",
      "Solving environment: ...working... done\n",
      "\u001b[91m\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.5.11\n",
      "  latest version: 4.6.7\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "ncurses-6.0          | 920 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "ncurses-6.0          | 920 KB    | #######9   |  79% \u001b[0m\u001b[91m\n",
      "ncurses-6.0          | 920 KB    | ########8  |  88% \u001b[0m\u001b[91m\n",
      "ncurses-6.0          | 920 KB    | #########8 |  99% \u001b[0m\u001b[91m\n",
      "ncurses-6.0          | 920 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "libffi-3.2.1         | 43 KB     |            |   0% \u001b[0m\u001b[91m\n",
      "libffi-3.2.1         | 43 KB     | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "xz-5.2.4             | 366 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "xz-5.2.4             | 366 KB    | #########4 |  95% \u001b[0m\u001b[91m\n",
      "xz-5.2.4             | 366 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "libstdcxx-ng-8.2.0   | 2.9 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "libstdcxx-ng-8.2.0   | 2.9 MB    | #######7   |  77% \u001b[0m\u001b[91m\n",
      "libstdcxx-ng-8.2.0   | 2.9 MB    | #########4 |  95% \u001b[0m\u001b[91m\n",
      "libstdcxx-ng-8.2.0   | 2.9 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "tk-8.6.8             | 3.1 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "tk-8.6.8             | 3.1 MB    | #######6   |  77% \u001b[0m\u001b[91m\n",
      "tk-8.6.8             | 3.1 MB    | ########7  |  87% \u001b[0m\u001b[91m\n",
      "tk-8.6.8             | 3.1 MB    | #########5 |  96% \u001b[0m\u001b[91m\n",
      "tk-8.6.8             | 3.1 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "pip-19.0.3           | 1.9 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "pip-19.0.3           | 1.9 MB    | #######9   |  79% \u001b[0m\u001b[91m\n",
      "pip-19.0.3           | 1.9 MB    | #########4 |  94% \u001b[0m\u001b[91m\n",
      "pip-19.0.3           | 1.9 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "certifi-2018.11.29   | 146 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "certifi-2018.11.29   | 146 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "openssl-1.0.2r       | 3.2 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "openssl-1.0.2r       | 3.2 MB    | #######6   |  76% \u001b[0m\u001b[91m\n",
      "openssl-1.0.2r       | 3.2 MB    | #########5 |  96% \u001b[0m\u001b[91m\n",
      "openssl-1.0.2r       | 3.2 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "libedit-3.1          | 171 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "libedit-3.1          | 171 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "ca-certificates-2019 | 126 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "ca-certificates-2019 | 126 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "sqlite-3.23.1        | 1.5 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "sqlite-3.23.1        | 1.5 MB    | ########   |  80% \u001b[0m\u001b[91m\n",
      "sqlite-3.23.1        | 1.5 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "readline-7.0         | 1.1 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "readline-7.0         | 1.1 MB    | ########   |  81% \u001b[0m\u001b[91m\n",
      "readline-7.0         | 1.1 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "libgcc-ng-8.2.0      | 7.6 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "libgcc-ng-8.2.0      | 7.6 MB    | #######5   |  75% \u001b[0m\u001b[91m\n",
      "libgcc-ng-8.2.0      | 7.6 MB    | #########7 |  98% \u001b[0m\u001b[91m\n",
      "libgcc-ng-8.2.0      | 7.6 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "wheel-0.33.1         | 39 KB     |            |   0% \u001b[0m\u001b[91m\n",
      "wheel-0.33.1         | 39 KB     | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "setuptools-40.8.0    | 647 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "setuptools-40.8.0    | 647 KB    | ########4  |  85% \u001b[0m\u001b[91m\n",
      "setuptools-40.8.0    | 647 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "python-3.6.2         | 27.0 MB   |            |   0% \u001b[0m\u001b[91m\n",
      "python-3.6.2         | 27.0 MB   | ##1        |  22% \u001b[0m\u001b[91m\n",
      "python-3.6.2         | 27.0 MB   | ####1      |  42% \u001b[0m\u001b[91m\n",
      "python-3.6.2         | 27.0 MB   | ######2    |  63% \u001b[0m\u001b[91m\n",
      "python-3.6.2         | 27.0 MB   | #######6   |  76% \u001b[0m\u001b[91m\n",
      "python-3.6.2         | 27.0 MB   | ########6  |  86% \u001b[0m\u001b[91m\n",
      "python-3.6.2         | 27.0 MB   | #########3 |  94% \u001b[0m\u001b[91m\n",
      "python-3.6.2         | 27.0 MB   | #########8 |  99% \u001b[0m\u001b[91m\n",
      "python-3.6.2         | 27.0 MB   | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "zlib-1.2.11          | 120 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "zlib-1.2.11          | 120 KB    | ########## | 100% \u001b[0m\n",
      "Downloading and Extracting Packages\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "Collecting azureml-defaults (from -r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/64/0a/e1c2b6e2a591dda0a1a8ee3a143264484d1db46fef80eb34f652ac7a3846/azureml_defaults-1.0.17-py2.py3-none-any.whl\n",
      "Collecting tensorflow-gpu==1.10.0 (from -r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/64/ca/830b7cedb073ae264d215d51bd18d7cff7a2a47e39d79f6fa23edae17bb2/tensorflow_gpu-1.10.0-cp36-cp36m-manylinux1_x86_64.whl (253.2MB)\n",
      "Collecting pydicom (from -r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/43/88/d3c419ab2e753e7651510882a53219373e78fb55294cb247dffd3934ea55/pydicom-1.2.2-py2.py3-none-any.whl (7.0MB)\n",
      "Collecting keras (from -r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\n",
      "Collecting scikit-image (from -r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/24/06/d560630eb9e36d90d69fe57d9ff762d8f501664ce478b8a0ae132b3c3008/scikit_image-0.14.2-cp36-cp36m-manylinux1_x86_64.whl (25.3MB)\n",
      "Collecting scikit-learn (from -r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/0d/3a/b92670f5c368c20329ecc4c255993fae7934564d485c3ed7ea7b8da7f741/scikit_learn-0.20.2-cp36-cp36m-manylinux1_x86_64.whl (5.4MB)\n",
      "Collecting scipy (from -r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 7))\n",
      "  Downloading https://files.pythonhosted.org/packages/7f/5f/c48860704092933bf1c4c1574a8de1ffd16bf4fde8bab190d747598844b2/scipy-1.2.1-cp36-cp36m-manylinux1_x86_64.whl (24.8MB)\n",
      "Collecting argparse (from -r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 8))\n",
      "  Downloading https://files.pythonhosted.org/packages/f2/94/3af39d34be01a24a6e65433d19e107099374224905f1e0cc6bbe1fd22a2f/argparse-1.4.0-py2.py3-none-any.whl\n",
      "Collecting opencv-contrib-python-headless (from -r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 9))\n",
      "  Downloading https://files.pythonhosted.org/packages/11/25/eb8dd0fac7ddc3ae7b645bb527c84f1237cf6c749cff4df45cb7c1a36bd7/opencv_contrib_python_headless-4.0.0.21-cp36-cp36m-manylinux1_x86_64.whl (24.6MB)\n",
      "Collecting pillow (from -r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 10))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading https://files.pythonhosted.org/packages/85/5e/e91792f198bbc5a0d7d3055ad552bc4062942d27eaf75c3e2783cf64eae5/Pillow-5.4.1-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
      "Collecting numpy (from -r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 11))\n",
      "  Downloading https://files.pythonhosted.org/packages/35/d5/4f8410ac303e690144f0a0603c4b8fd3b986feb2749c435f7cdbb288f17e/numpy-1.16.2-cp36-cp36m-manylinux1_x86_64.whl (17.3MB)\n",
      "Collecting pandas (from -r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 12))\n",
      "  Downloading https://files.pythonhosted.org/packages/e6/de/a0d3defd8f338eaf53ef716e40ef6d6c277c35d50e09b586e170169cdf0d/pandas-0.24.1-cp36-cp36m-manylinux1_x86_64.whl (10.1MB)\n",
      "Collecting matplotlib (from -r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 13))\n",
      "  Downloading https://files.pythonhosted.org/packages/71/07/16d781df15be30df4acfd536c479268f1208b2dfbc91e9ca5d92c9caf673/matplotlib-3.0.2-cp36-cp36m-manylinux1_x86_64.whl (12.9MB)\n",
      "Collecting azureml-core==1.0.17.* (from azureml-defaults->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/54/8e/4e57078e34ce48d089c5e427327ebdb7a5002d807140a90948c3635bfc2e/azureml_core-1.0.17.1-py2.py3-none-any.whl (719kB)\n",
      "Collecting applicationinsights>=0.11.7 (from azureml-defaults->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/e3/c8/7848a0dd85158930b859eb8be1e38fc76a91f0a040d491723ebb356d7358/applicationinsights-0.11.7-py2.py3-none-any.whl (56kB)\n",
      "Collecting astor>=0.6.0 (from tensorflow-gpu==1.10.0->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/35/6b/11530768cac581a12952a2aad00e1526b89d242d0b9f59534ef6e6a1752f/astor-0.7.1-py2.py3-none-any.whl\n",
      "Collecting setuptools<=39.1.0 (from tensorflow-gpu==1.10.0->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/8c/10/79282747f9169f21c053c562a0baa21815a8c7879be97abd930dbcf862e8/setuptools-39.1.0-py2.py3-none-any.whl (566kB)\n",
      "Collecting protobuf>=3.6.0 (from tensorflow-gpu==1.10.0->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/c2/f9/28787754923612ca9bfdffc588daa05580ed70698add063a5629d1a4209d/protobuf-3.6.1-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
      "Collecting grpcio>=1.8.6 (from tensorflow-gpu==1.10.0->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/f4/dc/5503d89e530988eb7a1aed337dcb456ef8150f7c06132233bd9e41ec0215/grpcio-1.19.0-cp36-cp36m-manylinux1_x86_64.whl (10.8MB)\n",
      "Collecting absl-py>=0.1.6 (from tensorflow-gpu==1.10.0->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/31/bc/ab68120d1d89ae23b694a55fe2aece2f91194313b71f9b05a80b32d3c24b/absl-py-0.7.0.tar.gz (96kB)\n",
      "Collecting tensorboard<1.11.0,>=1.10.0 (from tensorflow-gpu==1.10.0->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/c6/17/ecd918a004f297955c30b4fffbea100b1606c225dbf0443264012773c3ff/tensorboard-1.10.0-py3-none-any.whl (3.3MB)\n",
      "Requirement already satisfied: wheel>=0.26 in /azureml-envs/azureml_d0a02ed84b7b88651f66388ea6efaa54/lib/python3.6/site-packages (from tensorflow-gpu==1.10.0->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 2)) (0.33.1)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-gpu==1.10.0->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\n",
      "Collecting gast>=0.2.0 (from tensorflow-gpu==1.10.0->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
      "Collecting six>=1.10.0 (from tensorflow-gpu==1.10.0->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whl\n",
      "Collecting keras-applications>=1.0.6 (from keras->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/90/85/64c82949765cfb246bbdaf5aca2d55f400f792655927a017710a78445def/Keras_Applications-1.0.7-py2.py3-none-any.whl (51kB)\n",
      "Collecting pyyaml (from keras->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/9e/a3/1d13970c3f36777c583f136c136f804d70f500168edc1edea6daa7200769/PyYAML-3.13.tar.gz (270kB)\n",
      "Collecting h5py (from keras->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/30/99/d7d4fbf2d02bb30fb76179911a250074b55b852d34e98dd452a9f394ac06/h5py-2.9.0-cp36-cp36m-manylinux1_x86_64.whl (2.8MB)\n",
      "Collecting keras-preprocessing>=1.0.5 (from keras->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/c0/bf/0315ef6a9fd3fc2346e85b0ff1f5f83ca17073f2c31ac719ab2e4da0d4a3/Keras_Preprocessing-1.0.9-py2.py3-none-any.whl (59kB)\n",
      "Collecting networkx>=1.8 (from scikit-image->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/f3/f4/7e20ef40b118478191cec0b58c3192f822cace858c19505c7670961b76b2/networkx-2.2.zip (1.7MB)\n",
      "Collecting dask[array]>=1.0.0 (from scikit-image->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/06/d9/335788a25a72d4d4edbb01d6df3ca9dfc372737e1145cf73cda3a7d5e7de/dask-1.1.2-py2.py3-none-any.whl (704kB)\n",
      "Collecting PyWavelets>=0.4.0 (from scikit-image->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/92/9a/2816f258df2e4e5885ebcb7695619c254f0d8f94f700c204c3eb77e8c0fd/PyWavelets-1.0.2-cp36-cp36m-manylinux1_x86_64.whl (4.4MB)\n",
      "Collecting cloudpickle>=0.2.1 (from scikit-image->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/47/d5/efa7cacef5d3bdcd71d7053a698fb9b64a20fff5cb3c592efefa53ea5578/cloudpickle-0.8.0-py2.py3-none-any.whl\n",
      "Collecting pytz>=2011k (from pandas->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 12))\n",
      "  Downloading https://files.pythonhosted.org/packages/61/28/1d3920e4d1d50b19bc5d24398a7cd85cc7b9a75a490570d5a30c57622d34/pytz-2018.9-py2.py3-none-any.whl (510kB)\n",
      "Collecting python-dateutil>=2.5.0 (from pandas->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 12))\n",
      "  Downloading https://files.pythonhosted.org/packages/41/17/c62faccbfbd163c7f57f3844689e3a78bae1f403648a6afb1d0866d87fbb/python_dateutil-2.8.0-py2.py3-none-any.whl (226kB)\n",
      "Collecting cycler>=0.10 (from matplotlib->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 13))\n",
      "  Downloading https://files.pythonhosted.org/packages/f7/d2/e07d3ebb2bd7af696440ce7e754c59dd546ffe1bbe732c8ab68b9c834e61/cycler-0.10.0-py2.py3-none-any.whl\n",
      "Collecting kiwisolver>=1.0.1 (from matplotlib->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 13))\n",
      "  Downloading https://files.pythonhosted.org/packages/69/a7/88719d132b18300b4369fbffa741841cfd36d1e637e1990f27929945b538/kiwisolver-1.0.1-cp36-cp36m-manylinux1_x86_64.whl (949kB)\n",
      "Collecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 (from matplotlib->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 13))\n",
      "  Downloading https://files.pythonhosted.org/packages/de/0a/001be530836743d8be6c2d85069f46fecf84ac6c18c7f5fb8125ee11d854/pyparsing-2.3.1-py2.py3-none-any.whl (61kB)\n",
      "Collecting ndg-httpsclient (from azureml-core==1.0.17.*->azureml-defaults->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/fb/67/c2f508c00ed2a6911541494504b7cac16fe0b0473912568df65fd1801132/ndg_httpsclient-0.5.1-py3-none-any.whl\n",
      "Collecting docker (from azureml-core==1.0.17.*->azureml-defaults->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/7e/3c/b610f22b170b0f8fe4d8f78974878e116562389f666f99e6549567eb9d87/docker-3.7.0-py2.py3-none-any.whl (133kB)\n",
      "Collecting azure-mgmt-resource>=1.2.1 (from azureml-core==1.0.17.*->azureml-defaults->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/2b/2e/e79a278bedfc21308ab0c632759cfda5d7ff02d62260bcc4632449937dcf/azure_mgmt_resource-2.1.0-py2.py3-none-any.whl (757kB)\n",
      "Collecting azure-graphrbac>=0.40.0 (from azureml-core==1.0.17.*->azureml-defaults->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/da/a8/3d3d6fe8458b2b07bad10195c79928ea9ba87b5cc0c08903b387dd27c6f0/azure_graphrbac-0.53.0-py2.py3-none-any.whl (108kB)\n",
      "Collecting azure-mgmt-keyvault>=0.40.0 (from azureml-core==1.0.17.*->azureml-defaults->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/49/de/0d69aedae7c5f6428314640b65947203ab80409c12b5d4e66fb5b7a4182e/azure_mgmt_keyvault-1.1.0-py2.py3-none-any.whl (111kB)\n",
      "Collecting backports.tempfile (from azureml-core==1.0.17.*->azureml-defaults->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/b4/5c/077f910632476281428fe254807952eb47ca78e720d059a46178c541e669/backports.tempfile-1.0-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-storage>=1.5.0 (from azureml-core==1.0.17.*->azureml-defaults->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/d9/87/ab44b9d9627ff91825ba5f5a39092ebfe97a90679008609db4c479036591/azure_mgmt_storage-3.1.1-py2.py3-none-any.whl (696kB)\n",
      "Collecting msrestazure>=0.4.33 (from azureml-core==1.0.17.*->azureml-defaults->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/46/ba/7870308e3d3b4b3956880eed2df20669a5690436793e6fc1442c8b73e01c/msrestazure-0.6.0-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-containerregistry>=2.0.0 (from azureml-core==1.0.17.*->azureml-defaults->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/7a/4b/06040d992f93531e32c5f7cf7884f3edfec11f76f802dd9224c1116c3129/azure_mgmt_containerregistry-2.7.0-py2.py3-none-any.whl (509kB)\n",
      "Collecting adal>=1.2.0 (from azureml-core==1.0.17.*->azureml-defaults->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/00/72/53dce9e4f5d6c1aa57b8d408cb34dff1969ecbf10ab7e678f32c5e0e2397/adal-1.2.1-py2.py3-none-any.whl (52kB)\n",
      "Collecting msrest>=0.5.1 (from azureml-core==1.0.17.*->azureml-defaults->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/eb/96/1cf56e4cfd221b7f6eb6ab096dc23b0d21361393f0784276531e49b0b2a1/msrest-0.6.4-py2.py3-none-any.whl (81kB)\n",
      "Collecting PyJWT (from azureml-core==1.0.17.*->azureml-defaults->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/87/8b/6a9f14b5f781697e51259d81657e6048fd31a113229cf346880bb7545565/PyJWT-1.7.1-py2.py3-none-any.whl\n",
      "Collecting pyopenssl (from azureml-core==1.0.17.*->azureml-defaults->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/01/c8/ceb170d81bd3941cbeb9940fc6cc2ef2ca4288d0ca8929ea4db5905d904d/pyOpenSSL-19.0.0-py2.py3-none-any.whl (53kB)\n",
      "Collecting jmespath (from azureml-core==1.0.17.*->azureml-defaults->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/83/94/7179c3832a6d45b266ddb2aac329e101367fbdb11f425f13771d27f225bb/jmespath-0.9.4-py2.py3-none-any.whl\n",
      "Collecting jsonpickle (from azureml-core==1.0.17.*->azureml-defaults->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/dc/12/8c44eabb501e2bc0aec0dd152b328074d98a50968d3a02be28f6037f0c6a/jsonpickle-1.1-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-authorization>=0.40.0 (from azureml-core==1.0.17.*->azureml-defaults->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/a1/71/9a20913e92771b3c23564f1bea54d376d09fb30a75585087c70b769d75c8/azure_mgmt_authorization-0.51.1-py2.py3-none-any.whl (111kB)\n",
      "Collecting cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,<2.6 (from azureml-core==1.0.17.*->azureml-defaults->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/98/71/e632e222f34632e0527dd41799f7847305e701f38f512d81bdf96009bca4/cryptography-2.5-cp34-abi3-manylinux1_x86_64.whl (2.4MB)\n",
      "Collecting requests>=2.19.1 (from azureml-core==1.0.17.*->azureml-defaults->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/7d/e3/20f3d364d6c8e5d2353c72a67778eb189176f08e873c9900e10c0287b84b/requests-2.21.0-py2.py3-none-any.whl (57kB)\n",
      "Collecting azure-common>=1.1.12 (from azureml-core==1.0.17.*->azureml-defaults->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading https://files.pythonhosted.org/packages/c3/f8/46248b201fd38b7e93c6da644e2fc3bc5a39118f253562751fd295a8cc77/azure_common-1.1.18-py2.py3-none-any.whl\n",
      "Collecting paramiko>=2.0.8 (from azureml-core==1.0.17.*->azureml-defaults->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/cf/ae/94e70d49044ccc234bfdba20114fa947d7ba6eb68a2e452d89b920e62227/paramiko-2.4.2-py2.py3-none-any.whl (193kB)\n",
      "Collecting pathspec (from azureml-core==1.0.17.*->azureml-defaults->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/84/2a/bfee636b1e2f7d6e30dd74f49201ccfa5c3cf322d44929ecc6c137c486c5/pathspec-0.5.9.tar.gz\n",
      "Collecting contextlib2 (from azureml-core==1.0.17.*->azureml-defaults->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/a2/71/8273a7eeed0aff6a854237ab5453bc9aa67deb49df4832801c21f0ff3782/contextlib2-0.5.5-py2.py3-none-any.whl\n",
      "Collecting urllib3>=1.23 (from azureml-core==1.0.17.*->azureml-defaults->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/62/00/ee1d7de624db8ba7090d1226aebefab96a2c71cd5cfa7629d6ad3f61b79e/urllib3-1.24.1-py2.py3-none-any.whl (118kB)\n",
      "Collecting ruamel.yaml<=0.15.51,>=0.15.35 (from azureml-core==1.0.17.*->azureml-defaults->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/d2/7f/9bb3ba89ceab600c4a0ea75d638ea945215ca3458ac6528e0e39fa3254e4/ruamel.yaml-0.15.51-cp36-cp36m-manylinux1_x86_64.whl (640kB)\n",
      "Collecting SecretStorage (from azureml-core==1.0.17.*->azureml-defaults->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/82/59/cb226752e20d83598d7fdcabd7819570b0329a61db07cfbdd21b2ef546e3/SecretStorage-3.1.1-py3-none-any.whl\n",
      "Collecting markdown>=2.6.8 (from tensorboard<1.11.0,>=1.10.0->tensorflow-gpu==1.10.0->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/7a/6b/5600647404ba15545ec37d2f7f58844d690baf2f81f3a60b862e48f29287/Markdown-3.0.1-py2.py3-none-any.whl (89kB)\n",
      "Collecting werkzeug>=0.11.10 (from tensorboard<1.11.0,>=1.10.0->tensorflow-gpu==1.10.0->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/20/c4/12e3e56473e52375aa29c4764e70d1b8f3efa6682bef8d0aae04fe335243/Werkzeug-0.14.1-py2.py3-none-any.whl (322kB)\n",
      "Collecting decorator>=4.3.0 (from networkx>=1.8->scikit-image->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/f1/cd/7c8240007e9716b14679bc217a1baefa4432aa30394f7e2ec40a52b1a708/decorator-4.3.2-py2.py3-none-any.whl\n",
      "Collecting toolz>=0.7.3; extra == \"array\" (from dask[array]>=1.0.0->scikit-image->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/14/d0/a73c15bbeda3d2e7b381a36afb0d9cd770a9f4adc5d1532691013ba881db/toolz-0.9.0.tar.gz (45kB)\n",
      "Collecting pyasn1>=0.1.1 (from ndg-httpsclient->azureml-core==1.0.17.*->azureml-defaults->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/7b/7c/c9386b82a25115cccf1903441bba3cbadcfae7b678a20167347fa8ded34c/pyasn1-0.4.5-py2.py3-none-any.whl (73kB)\n",
      "Collecting websocket-client>=0.32.0 (from docker->azureml-core==1.0.17.*->azureml-defaults->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/38/54/684db2ba1b7a203602808446b8686ee786f93b4a7e080cdc440cc7e06e56/websocket_client-0.55.0-py2.py3-none-any.whl (200kB)\n",
      "Collecting docker-pycreds>=0.4.0 (from docker->azureml-core==1.0.17.*->azureml-defaults->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-nspkg>=2.0.0 (from azure-mgmt-keyvault>=0.40.0->azureml-core==1.0.17.*->azureml-defaults->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/b3/c2/af4b47845f27dc7d206ed4908b9e580f8bc94a4b2f3956a0d87c40719d90/azure_mgmt_nspkg-3.0.2-py3-none-any.whl\n",
      "Collecting backports.weakref (from backports.tempfile->azureml-core==1.0.17.*->azureml-defaults->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/88/ec/f598b633c3d5ffe267aaada57d961c94fdfa183c5c3ebda2b6d151943db6/backports.weakref-1.0.post1-py2.py3-none-any.whl\n",
      "Collecting isodate>=0.6.0 (from msrest>=0.5.1->azureml-core==1.0.17.*->azureml-defaults->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/9b/9f/b36f7774ff5ea8e428fdcfc4bb332c39ee5b9362ddd3d40d9516a55221b2/isodate-0.6.0-py2.py3-none-any.whl (45kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /azureml-envs/azureml_d0a02ed84b7b88651f66388ea6efaa54/lib/python3.6/site-packages (from msrest>=0.5.1->azureml-core==1.0.17.*->azureml-defaults->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 1)) (2018.11.29)\n",
      "Collecting requests-oauthlib>=0.5.0 (from msrest>=0.5.1->azureml-core==1.0.17.*->azureml-defaults->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/c2/e2/9fd03d55ffb70fe51f587f20bcf407a6927eb121de86928b34d162f0b1ac/requests_oauthlib-1.2.0-py2.py3-none-any.whl\n",
      "Collecting asn1crypto>=0.21.0 (from cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,<2.6->azureml-core==1.0.17.*->azureml-defaults->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/ea/cd/35485615f45f30a510576f1a56d1e0a7ad7bd8ab5ed7cdc600ef7cd06222/asn1crypto-0.24.0-py2.py3-none-any.whl (101kB)\n",
      "Collecting cffi!=1.11.3,>=1.8 (from cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,<2.6->azureml-core==1.0.17.*->azureml-defaults->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/20/f7/87b62a8895bf7c93e907b05b97bc4459c81a38a61151f03a6eae13d863aa/cffi-1.12.2-cp36-cp36m-manylinux1_x86_64.whl (428kB)\n",
      "Collecting idna<2.9,>=2.5 (from requests>=2.19.1->azureml-core==1.0.17.*->azureml-defaults->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/14/2c/cd551d81dbe15200be1cf41cd03869a46fe7226e7450af7a6545bfc474c9/idna-2.8-py2.py3-none-any.whl (58kB)\n",
      "Collecting chardet<3.1.0,>=3.0.2 (from requests>=2.19.1->azureml-core==1.0.17.*->azureml-defaults->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl (133kB)\n",
      "Collecting bcrypt>=3.1.3 (from paramiko>=2.0.8->azureml-core==1.0.17.*->azureml-defaults->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/d0/79/79a4d167a31cc206117d9b396926615fa9c1fdbd52017bcced80937ac501/bcrypt-3.1.6-cp34-abi3-manylinux1_x86_64.whl (55kB)\n",
      "Collecting pynacl>=1.0.1 (from paramiko>=2.0.8->azureml-core==1.0.17.*->azureml-defaults->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/27/15/2cd0a203f318c2240b42cd9dd13c931ddd61067809fee3479f44f086103e/PyNaCl-1.3.0-cp34-abi3-manylinux1_x86_64.whl (759kB)\n",
      "Collecting jeepney (from SecretStorage->azureml-core==1.0.17.*->azureml-defaults->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/2b/f7/ff23b9b59534f501d47c327576aadda59da5b83d76ff837e6075bc325b9f/jeepney-0.4-py3-none-any.whl (59kB)\n",
      "Collecting azure-nspkg>=3.0.0 (from azure-mgmt-nspkg>=2.0.0->azure-mgmt-keyvault>=0.40.0->azureml-core==1.0.17.*->azureml-defaults->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/c4/0c/c562be95a9a2ed52454f598571cf300b1114d0db2aa27f5b8ed3bb9cd0c0/azure_nspkg-3.0.2-py3-none-any.whl\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.5.0->msrest>=0.5.1->azureml-core==1.0.17.*->azureml-defaults->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/16/95/699466b05b72b94a41f662dc9edf87fda4289e3602ecd42d27fcaddf7b56/oauthlib-3.0.1-py2.py3-none-any.whl (142kB)\n",
      "Collecting pycparser (from cffi!=1.11.3,>=1.8->cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,<2.6->azureml-core==1.0.17.*->azureml-defaults->-r /azureml-setup/condaenv.5mpabhud.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/68/9e/49196946aee219aead1290e00d1e7fdeab8567783e83e1b9ab5585e6206a/pycparser-2.19.tar.gz (158kB)\n",
      "Building wheels for collected packages: absl-py, termcolor, gast, pyyaml, networkx, pathspec, toolz, pycparser\n",
      "  Building wheel for absl-py (setup.py): started\n",
      "  Building wheel for absl-py (setup.py): finished with status 'done'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Stored in directory: /root/.cache/pip/wheels/90/db/f8/2c3101f72ef1ad434e4662853174126ce30201a3e163dcbeca\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/7c/06/54/bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6\n",
      "  Building wheel for gast (setup.py): started\n",
      "  Building wheel for gast (setup.py): finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
      "  Building wheel for pyyaml (setup.py): started\n",
      "  Building wheel for pyyaml (setup.py): finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/ad/da/0c/74eb680767247273e2cf2723482cb9c924fe70af57c334513f\n",
      "  Building wheel for networkx (setup.py): started\n",
      "  Building wheel for networkx (setup.py): finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/68/f8/29/b53346a112a07d30a5a84d53f19aeadaa1a474897c0423af91\n",
      "  Building wheel for pathspec (setup.py): started\n",
      "  Building wheel for pathspec (setup.py): finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/45/cb/7e/ce6e6062c69446e39e328170524ca8213498bc66a74c6a210b\n",
      "  Building wheel for toolz (setup.py): started\n",
      "  Building wheel for toolz (setup.py): finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/f4/0c/f6/ce6b2d1aa459ee97cc3c0f82236302bd62d89c86c700219463\n",
      "  Building wheel for pycparser (setup.py): started\n",
      "  Building wheel for pycparser (setup.py): finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/f2/9a/90/de94f8556265ddc9d9c8b271b0f63e57b26fb1d67a45564511\n",
      "Successfully built absl-py termcolor gast pyyaml networkx pathspec toolz pycparser\n",
      "\u001b[91mtensorflow-gpu 1.10.0 has requirement numpy<=1.14.5,>=1.13.3, but you'll have numpy 1.16.2 which is incompatible.\n",
      "\u001b[0mInstalling collected packages: asn1crypto, six, pycparser, cffi, cryptography, pyopenssl, pyasn1, ndg-httpsclient, websocket-client, idna, urllib3, chardet, requests, docker-pycreds, docker, python-dateutil, PyJWT, adal, isodate, oauthlib, requests-oauthlib, msrest, msrestazure, azure-common, azure-mgmt-resource, azure-graphrbac, azure-nspkg, azure-mgmt-nspkg, azure-mgmt-keyvault, backports.weakref, backports.tempfile, azure-mgmt-storage, pyyaml, azure-mgmt-containerregistry, jmespath, jsonpickle, azure-mgmt-authorization, pytz, bcrypt, pynacl, paramiko, pathspec, contextlib2, ruamel.yaml, jeepney, SecretStorage, azureml-core, applicationinsights, azureml-defaults, astor, setuptools, protobuf, numpy, grpcio, absl-py, markdown, werkzeug, tensorboard, termcolor, gast, tensorflow-gpu, pydicom, h5py, keras-applications, scipy, keras-preprocessing, keras, decorator, networkx, toolz, dask, cycler, kiwisolver, pyparsing, matplotlib, pillow, PyWavelets, cloudpickle, scikit-image, scikit-learn, argparse, opencv-contrib-python-headless, pandas\n",
      "  Found existing installation: setuptools 40.8.0\n",
      "    Uninstalling setuptools-40.8.0:\n",
      "      Successfully uninstalled setuptools-40.8.0\n",
      "Successfully installed PyJWT-1.7.1 PyWavelets-1.0.2 SecretStorage-3.1.1 absl-py-0.7.0 adal-1.2.1 applicationinsights-0.11.7 argparse-1.4.0 asn1crypto-0.24.0 astor-0.7.1 azure-common-1.1.18 azure-graphrbac-0.53.0 azure-mgmt-authorization-0.51.1 azure-mgmt-containerregistry-2.7.0 azure-mgmt-keyvault-1.1.0 azure-mgmt-nspkg-3.0.2 azure-mgmt-resource-2.1.0 azure-mgmt-storage-3.1.1 azure-nspkg-3.0.2 azureml-core-1.0.17.1 azureml-defaults-1.0.17 backports.tempfile-1.0 backports.weakref-1.0.post1 bcrypt-3.1.6 cffi-1.12.2 chardet-3.0.4 cloudpickle-0.8.0 contextlib2-0.5.5 cryptography-2.5 cycler-0.10.0 dask-1.1.2 decorator-4.3.2 docker-3.7.0 docker-pycreds-0.4.0 gast-0.2.2 grpcio-1.19.0 h5py-2.9.0 idna-2.8 isodate-0.6.0 jeepney-0.4 jmespath-0.9.4 jsonpickle-1.1 keras-2.2.4 keras-applications-1.0.7 keras-preprocessing-1.0.9 kiwisolver-1.0.1 markdown-3.0.1 matplotlib-3.0.2 msrest-0.6.4 msrestazure-0.6.0 ndg-httpsclient-0.5.1 networkx-2.2 numpy-1.16.2 oauthlib-3.0.1 opencv-contrib-python-headless-4.0.0.21 pandas-0.24.1 paramiko-2.4.2 pathspec-0.5.9 pillow-5.4.1 protobuf-3.6.1 pyasn1-0.4.5 pycparser-2.19 pydicom-1.2.2 pynacl-1.3.0 pyopenssl-19.0.0 pyparsing-2.3.1 python-dateutil-2.8.0 pytz-2018.9 pyyaml-3.13 requests-2.21.0 requests-oauthlib-1.2.0 ruamel.yaml-0.15.51 scikit-image-0.14.2 scikit-learn-0.20.2 scipy-1.2.1 setuptools-39.1.0 six-1.12.0 tensorboard-1.10.0 tensorflow-gpu-1.10.0 termcolor-1.1.0 toolz-0.9.0 urllib3-1.24.1 websocket-client-0.55.0 werkzeug-0.14.1\n",
      "\u001b[91m\n",
      "\u001b[0m#\n",
      "# To activate this environment, use:\n",
      "# > source activate /azureml-envs/azureml_d0a02ed84b7b88651f66388ea6efaa54\n",
      "#\n",
      "# To deactivate an active environment, use:\n",
      "# > source deactivate\n",
      "#\n",
      "\n",
      "Removing intermediate container ec1de67c562d\n",
      " ---> 759b009819fc\n",
      "Step 9/13 : ENV PATH /azureml-envs/azureml_d0a02ed84b7b88651f66388ea6efaa54/bin:$PATH\n",
      " ---> Running in 7791faeeaf0b\n",
      "Removing intermediate container 7791faeeaf0b\n",
      " ---> 1d6c9f8becf8\n",
      "Step 10/13 : ENV LD_LIBRARY_PATH /azureml-envs/azureml_d0a02ed84b7b88651f66388ea6efaa54/lib:$LD_LIBRARY_PATH\n",
      " ---> Running in 7716b943efed\n",
      "Removing intermediate container 7716b943efed\n",
      " ---> 6bc313c68d64\n",
      "Step 11/13 : COPY azureml-setup/spark_cache.py azureml-setup/log4j.properties /azureml-setup/\n",
      " ---> fb0c26e7355c\n",
      "Step 12/13 : RUN if [ $SPARK_HOME ]; then /bin/bash -c '$SPARK_HOME/bin/spark-submit \"--repositories\" \"https://mmlspark.azureedge.net/maven\" \"--packages\" \"com.microsoft.ml.spark:mmlspark_2.11:0.12\" /azureml-setup/spark_cache.py'; fi\n",
      " ---> Running in 2f80a13db6b7\n",
      "Removing intermediate container 2f80a13db6b7\n",
      " ---> 38aea4c87d37\n",
      "Step 13/13 : CMD [\"bash\"]\n",
      " ---> Running in 33bfb54a4495\n",
      "Removing intermediate container 33bfb54a4495\n",
      " ---> 7a3e24866c2d\n",
      "Successfully built 7a3e24866c2d\n",
      "Successfully tagged zaml3818199666.azurecr.io/azureml/azureml_34497fc6cae17407edce1ae59f990032:latest\n",
      "2019/02/28 16:10:40 Successfully executed container: acb_step_0\n",
      "2019/02/28 16:10:40 Executing step ID: acb_step_1. Working directory: '', Network: 'acb_default_network'\n",
      "2019/02/28 16:10:40 Pushing image: zaml3818199666.azurecr.io/azureml/azureml_34497fc6cae17407edce1ae59f990032:latest, attempt 1\n",
      "The push refers to repository [zaml3818199666.azurecr.io/azureml/azureml_34497fc6cae17407edce1ae59f990032]\n",
      "ed30fd04c260: Preparing\n",
      "3857fdc4134e: Preparing\n",
      "962cc0995e8c: Preparing\n",
      "3d512e761ab4: Preparing\n",
      "c94065c24caa: Preparing\n",
      "c5088e4dcdf9: Preparing\n",
      "1af194b284e7: Preparing\n",
      "a47a9623d406: Preparing\n",
      "51713b8e3669: Preparing\n",
      "bf847be1c797: Preparing\n",
      "553141bf0a37: Preparing\n",
      "5fb2a9818ab4: Preparing\n",
      "68dda0c9a8cd: Preparing\n",
      "f67191ae09b8: Preparing\n",
      "b2fd8b4c3da7: Preparing\n",
      "0de2edf7bff4: Preparing\n",
      "c5088e4dcdf9: Waiting\n",
      "1af194b284e7: Waiting\n",
      "a47a9623d406: Waiting\n",
      "51713b8e3669: Waiting\n",
      "bf847be1c797: Waiting\n",
      "553141bf0a37: Waiting\n",
      "5fb2a9818ab4: Waiting\n",
      "68dda0c9a8cd: Waiting\n",
      "f67191ae09b8: Waiting\n",
      "b2fd8b4c3da7: Waiting\n",
      "0de2edf7bff4: Waiting\n",
      "ed30fd04c260: Pushed\n",
      "c94065c24caa: Pushed\n",
      "3d512e761ab4: Pushed\n",
      "962cc0995e8c: Pushed\n",
      "a47a9623d406: Pushed\n",
      "51713b8e3669: Pushed\n",
      "1af194b284e7: Pushed\n",
      "5fb2a9818ab4: Pushed\n",
      "68dda0c9a8cd: Pushed\n",
      "f67191ae09b8: Pushed\n",
      "b2fd8b4c3da7: Pushed\n",
      "c5088e4dcdf9: Pushed\n",
      "553141bf0a37: Pushed\n",
      "bf847be1c797: Pushed\n",
      "0de2edf7bff4: Pushed\n",
      "3857fdc4134e: Pushed\n",
      "latest: digest: sha256:f73abfe683631050a427c314d60b801630a8e69831e19efab2cc8818b338c8b6 size: 3679\n",
      "2019/02/28 16:15:53 Successfully pushed image: zaml3818199666.azurecr.io/azureml/azureml_34497fc6cae17407edce1ae59f990032:latest\n",
      "2019/02/28 16:15:53 Step ID: acb_step_0 marked as successful (elapsed time in seconds: 292.860288)\n",
      "2019/02/28 16:15:53 Populating digests for step ID: acb_step_0...\n",
      "2019/02/28 16:15:55 Successfully populated digests for step ID: acb_step_0\n",
      "2019/02/28 16:15:55 Step ID: acb_step_1 marked as successful (elapsed time in seconds: 313.084087)\n",
      "2019/02/28 16:15:55 The following dependencies were found:\n",
      "2019/02/28 16:15:55 \n",
      "- image:\n",
      "    registry: zaml3818199666.azurecr.io\n",
      "    repository: azureml/azureml_34497fc6cae17407edce1ae59f990032\n",
      "    tag: latest\n",
      "    digest: sha256:f73abfe683631050a427c314d60b801630a8e69831e19efab2cc8818b338c8b6\n",
      "  runtime-dependency:\n",
      "    registry: mcr.microsoft.com\n",
      "    repository: azureml/base-gpu\n",
      "    tag: 0.2.1\n",
      "    digest: sha256:eb26cf5e4a6852a3b9029299ee17424b31f458b293066c11824135530617a073\n",
      "  git: {}\n",
      "\n",
      "Run ID: cbc was successful after 10m30s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Streaming azureml-logs/60_control_log.txt\n",
      "=========================================\n",
      "\n",
      "Streaming log file azureml-logs/60_control_log.txt\n",
      "\n",
      "Streaming azureml-logs/80_driver_log.txt\n",
      "========================================\n",
      "\n",
      "Using TensorFlow backend.\n",
      "/mnt/batch/tasks/shared/LS_root/jobs/zaml/azureml/keras-tf-exp-feb28_1551369917_43572d77/mounts/ctscands\n",
      "check the dicom file shape should be 100, 256,256 (100, 256, 256)\n",
      "keras_cnn_pydicom.py:92: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "  classifier.add(Conv2D(64, 3, 3, activation = 'relu'))\n",
      "keras_cnn_pydicom.py:96: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\")`\n",
      "  classifier.add(Conv2D(128, 3, 3, activation = 'relu'))\n",
      "keras_cnn_pydicom.py:101: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\")`\n",
      "  classifier.add(Conv2D(256, 3, 3, activation = 'relu'))\n",
      "keras_cnn_pydicom.py:118: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  validation_steps = 25)\n",
      "keras_cnn_pydicom.py:118: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., steps_per_epoch=100, validation_data=<keras_pre..., validation_steps=25, epochs=1)`\n",
      "  validation_steps = 25)\n",
      "Epoch 1/1\n",
      "2019-02-28 16:25:30.546750: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-02-28 16:25:30.687054: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 0 with properties: \n",
      "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
      "pciBusID: 3130:00:00.0\n",
      "totalMemory: 11.17GiB freeMemory: 11.10GiB\n",
      "2019-02-28 16:25:30.687090: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 0\n",
      "2019-02-28 16:25:30.962341: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-02-28 16:25:30.962389: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      0 \n",
      "2019-02-28 16:25:30.962397: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 0:   N \n",
      "2019-02-28 16:25:30.962643: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10758 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 3130:00:00.0, compute capability: 3.7)\n",
      "\n",
      "  1/100 [..............................] - ETA: 4:52 - loss: 0.6777 - acc: 0.6500\n",
      "  2/100 [..............................] - ETA: 2:29 - loss: 3.1412 - acc: 0.5250\n",
      "  3/100 [..............................] - ETA: 1:41 - loss: 2.3072 - acc: 0.5333\n",
      "  4/100 [>.............................] - ETA: 1:17 - loss: 1.9114 - acc: 0.5125\n",
      "  5/100 [>.............................] - ETA: 1:03 - loss: 1.6632 - acc: 0.5400\n",
      "  6/100 [>.............................] - ETA: 54s - loss: 1.5030 - acc: 0.5000 \n",
      "  7/100 [=>............................] - ETA: 47s - loss: 1.3804 - acc: 0.5643\n",
      "  8/100 [=>............................] - ETA: 42s - loss: 1.3004 - acc: 0.5500\n",
      "  9/100 [=>............................] - ETA: 38s - loss: 1.2269 - acc: 0.5778\n",
      " 10/100 [==>...........................] - ETA: 35s - loss: 1.1735 - acc: 0.5900\n",
      " 11/100 [==>...........................] - ETA: 32s - loss: 1.1306 - acc: 0.5818\n",
      " 12/100 [==>...........................] - ETA: 30s - loss: 1.0946 - acc: 0.5875\n",
      " 13/100 [==>...........................] - ETA: 28s - loss: 1.0591 - acc: 0.5885\n",
      " 14/100 [===>..........................] - ETA: 26s - loss: 1.0292 - acc: 0.5929\n",
      " 15/100 [===>..........................] - ETA: 24s - loss: 1.0043 - acc: 0.5900\n",
      " 16/100 [===>..........................] - ETA: 23s - loss: 0.9805 - acc: 0.5969\n",
      " 17/100 [====>.........................] - ETA: 22s - loss: 0.9647 - acc: 0.5912\n",
      " 18/100 [====>.........................] - ETA: 21s - loss: 0.9470 - acc: 0.6000\n",
      " 19/100 [====>.........................] - ETA: 20s - loss: 0.9262 - acc: 0.6079\n",
      " 20/100 [=====>........................] - ETA: 19s - loss: 0.9183 - acc: 0.6000\n",
      " 21/100 [=====>........................] - ETA: 18s - loss: 0.8990 - acc: 0.6071\n",
      " 22/100 [=====>........................] - ETA: 18s - loss: 0.8891 - acc: 0.6023\n",
      " 23/100 [=====>........................] - ETA: 17s - loss: 0.8761 - acc: 0.6043\n",
      " 24/100 [======>.......................] - ETA: 16s - loss: 0.8680 - acc: 0.6042\n",
      " 25/100 [======>.......................] - ETA: 16s - loss: 0.8588 - acc: 0.6060\n",
      " 26/100 [======>.......................] - ETA: 15s - loss: 0.8502 - acc: 0.6115\n",
      " 27/100 [=======>......................] - ETA: 15s - loss: 0.8410 - acc: 0.6148\n",
      " 28/100 [=======>......................] - ETA: 14s - loss: 0.8314 - acc: 0.6179\n",
      " 29/100 [=======>......................] - ETA: 14s - loss: 0.8239 - acc: 0.6224\n",
      " 30/100 [========>.....................] - ETA: 13s - loss: 0.8163 - acc: 0.6250\n",
      " 31/100 [========>.....................] - ETA: 13s - loss: 0.8086 - acc: 0.6306\n",
      " 32/100 [========>.....................] - ETA: 12s - loss: 0.8019 - acc: 0.6328\n",
      " 33/100 [========>.....................] - ETA: 12s - loss: 0.7949 - acc: 0.6333\n",
      " 34/100 [=========>....................] - ETA: 12s - loss: 0.7877 - acc: 0.6338\n",
      " 35/100 [=========>....................] - ETA: 11s - loss: 0.7781 - acc: 0.6414\n",
      " 36/100 [=========>....................] - ETA: 11s - loss: 0.7665 - acc: 0.6472\n",
      " 37/100 [==========>...................] - ETA: 11s - loss: 0.7598 - acc: 0.6500\n",
      " 38/100 [==========>...................] - ETA: 10s - loss: 0.7500 - acc: 0.6553\n",
      " 39/100 [==========>...................] - ETA: 10s - loss: 0.7459 - acc: 0.6564\n",
      " 40/100 [===========>..................] - ETA: 10s - loss: 0.7457 - acc: 0.6512\n",
      " 41/100 [===========>..................] - ETA: 10s - loss: 0.7428 - acc: 0.6524\n",
      " 42/100 [===========>..................] - ETA: 9s - loss: 0.7397 - acc: 0.6524 \n",
      " 43/100 [===========>..................] - ETA: 9s - loss: 0.7329 - acc: 0.6558\n",
      " 44/100 [============>.................] - ETA: 9s - loss: 0.7324 - acc: 0.6523\n",
      " 45/100 [============>.................] - ETA: 9s - loss: 0.7258 - acc: 0.6567\n",
      " 46/100 [============>.................] - ETA: 8s - loss: 0.7221 - acc: 0.6576\n",
      " 47/100 [=============>................] - ETA: 8s - loss: 0.7170 - acc: 0.6617\n",
      " 48/100 [=============>................] - ETA: 8s - loss: 0.7156 - acc: 0.6583\n",
      " 49/100 [=============>................] - ETA: 8s - loss: 0.7095 - acc: 0.6633\n",
      " 50/100 [==============>...............] - ETA: 7s - loss: 0.7050 - acc: 0.6650\n",
      " 51/100 [==============>...............] - ETA: 7s - loss: 0.6981 - acc: 0.6686\n",
      " 52/100 [==============>...............] - ETA: 7s - loss: 0.6922 - acc: 0.6712\n",
      " 53/100 [==============>...............] - ETA: 7s - loss: 0.6872 - acc: 0.6736\n",
      " 54/100 [===============>..............] - ETA: 7s - loss: 0.6921 - acc: 0.6731\n",
      " 55/100 [===============>..............] - ETA: 6s - loss: 0.6916 - acc: 0.6718\n",
      " 56/100 [===============>..............] - ETA: 6s - loss: 0.6880 - acc: 0.6741\n",
      " 57/100 [================>.............] - ETA: 6s - loss: 0.6857 - acc: 0.6746\n",
      " 58/100 [================>.............] - ETA: 6s - loss: 0.6800 - acc: 0.6776\n",
      " 59/100 [================>.............] - ETA: 6s - loss: 0.6777 - acc: 0.6771\n",
      " 60/100 [=================>............] - ETA: 5s - loss: 0.6760 - acc: 0.6783\n",
      " 61/100 [=================>............] - ETA: 5s - loss: 0.6726 - acc: 0.6803\n",
      " 62/100 [=================>............] - ETA: 5s - loss: 0.6693 - acc: 0.6823\n",
      " 63/100 [=================>............] - ETA: 5s - loss: 0.6656 - acc: 0.6849\n",
      " 64/100 [==================>...........] - ETA: 5s - loss: 0.6643 - acc: 0.6867\n",
      " 65/100 [==================>...........] - ETA: 5s - loss: 0.6613 - acc: 0.6877\n",
      " 66/100 [==================>...........] - ETA: 4s - loss: 0.6574 - acc: 0.6902\n",
      " 67/100 [===================>..........] - ETA: 4s - loss: 0.6560 - acc: 0.6903\n",
      " 68/100 [===================>..........] - ETA: 4s - loss: 0.6548 - acc: 0.6904\n",
      " 69/100 [===================>..........] - ETA: 4s - loss: 0.6537 - acc: 0.6913\n",
      " 70/100 [====================>.........] - ETA: 4s - loss: 0.6497 - acc: 0.6921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 71/100 [====================>.........] - ETA: 4s - loss: 0.6474 - acc: 0.6930\n",
      " 72/100 [====================>.........] - ETA: 3s - loss: 0.6437 - acc: 0.6937\n",
      " 73/100 [====================>.........] - ETA: 3s - loss: 0.6414 - acc: 0.6959\n",
      " 74/100 [=====================>........] - ETA: 3s - loss: 0.6402 - acc: 0.6959\n",
      " 75/100 [=====================>........] - ETA: 3s - loss: 0.6362 - acc: 0.6987\n",
      " 76/100 [=====================>........] - ETA: 3s - loss: 0.6340 - acc: 0.6980\n",
      " 77/100 [======================>.......] - ETA: 3s - loss: 0.6317 - acc: 0.6987\n",
      " 78/100 [======================>.......] - ETA: 3s - loss: 0.6282 - acc: 0.7006\n",
      " 79/100 [======================>.......] - ETA: 2s - loss: 0.6238 - acc: 0.7025\n",
      " 80/100 [=======================>......] - ETA: 2s - loss: 0.6200 - acc: 0.7056\n",
      " 81/100 [=======================>......] - ETA: 2s - loss: 0.6162 - acc: 0.7074\n",
      " 82/100 [=======================>......] - ETA: 2s - loss: 0.6125 - acc: 0.7098\n",
      " 83/100 [=======================>......] - ETA: 2s - loss: 0.6129 - acc: 0.7108\n",
      " 84/100 [========================>.....] - ETA: 2s - loss: 0.6089 - acc: 0.7131\n",
      " 85/100 [========================>.....] - ETA: 2s - loss: 0.6047 - acc: 0.7153\n",
      " 86/100 [========================>.....] - ETA: 1s - loss: 0.6026 - acc: 0.7169\n",
      " 87/100 [=========================>....] - ETA: 1s - loss: 0.5989 - acc: 0.7184\n",
      " 88/100 [=========================>....] - ETA: 1s - loss: 0.5950 - acc: 0.7210\n",
      " 89/100 [=========================>....] - ETA: 1s - loss: 0.5943 - acc: 0.7208\n",
      " 90/100 [==========================>...] - ETA: 1s - loss: 0.5935 - acc: 0.7211\n",
      " 91/100 [==========================>...] - ETA: 1s - loss: 0.5919 - acc: 0.7225\n",
      " 92/100 [==========================>...] - ETA: 1s - loss: 0.5892 - acc: 0.7234\n",
      " 93/100 [==========================>...] - ETA: 0s - loss: 0.5888 - acc: 0.7226\n",
      " 94/100 [===========================>..] - ETA: 0s - loss: 0.5864 - acc: 0.7239\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.5839 - acc: 0.7247\n",
      " 96/100 [===========================>..] - ETA: 0s - loss: 0.5799 - acc: 0.7271\n",
      " 97/100 [============================>.] - ETA: 0s - loss: 0.5770 - acc: 0.7284\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 0.5758 - acc: 0.7296\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.5720 - acc: 0.7313\n",
      "100/100 [==============================] - 15s 154ms/step - loss: 0.5694 - acc: 0.7325 - val_loss: 0.2527 - val_acc: 0.9000\n",
      "\n",
      "\n",
      "The experiment completed successfully. Finalizing run...\n",
      "Logging experiment finalizing status in history service\n",
      "Cleaning up all outstanding Run operations, waiting 300.0 seconds\n",
      "1 items cleaning up...\n",
      "Cleanup took 0.10098147392272949 seconds\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: keras-tf-exp-feb28_1551369917_43572d77\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'keras-tf-exp-feb28_1551369917_43572d77',\n",
       " 'target': 'gpucluster',\n",
       " 'status': 'Finalizing',\n",
       " 'startTimeUtc': '2019-02-28T16:20:56.883725Z',\n",
       " 'properties': {'azureml.runsource': 'experiment',\n",
       "  'ContentSnapshotId': 'bc15d3aa-34f1-4511-ad24-ccdc1deb9c90'},\n",
       " 'runDefinition': {'Script': 'keras_cnn_pydicom.py',\n",
       "  'Arguments': ['--data',\n",
       "   '$AZUREML_DATAREFERENCE_ctscands',\n",
       "   '--epoch',\n",
       "   '1',\n",
       "   '--save_model',\n",
       "   '/outputs'],\n",
       "  'SourceDirectoryDataStore': None,\n",
       "  'Framework': 0,\n",
       "  'Communicator': 0,\n",
       "  'Target': 'gpucluster',\n",
       "  'DataReferences': {'ctscands': {'DataStoreName': 'ctscands',\n",
       "    'Mode': 'Mount',\n",
       "    'PathOnDataStore': None,\n",
       "    'PathOnCompute': None,\n",
       "    'Overwrite': False}},\n",
       "  'JobName': None,\n",
       "  'AutoPrepareEnvironment': True,\n",
       "  'MaxRunDurationSeconds': None,\n",
       "  'NodeCount': 1,\n",
       "  'Environment': {'Python': {'InterpreterPath': 'python',\n",
       "    'UserManagedDependencies': False,\n",
       "    'CondaDependencies': {'name': 'project_environment',\n",
       "     'dependencies': ['python=3.6.2',\n",
       "      {'pip': ['azureml-defaults',\n",
       "        'tensorflow-gpu==1.10.0',\n",
       "        'pydicom',\n",
       "        'keras',\n",
       "        'scikit-image',\n",
       "        'scikit-learn',\n",
       "        'scipy',\n",
       "        'argparse',\n",
       "        'opencv-contrib-python-headless',\n",
       "        'pillow',\n",
       "        'numpy',\n",
       "        'pandas',\n",
       "        'matplotlib']}]}},\n",
       "   'EnvironmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE',\n",
       "    'NCCL_SOCKET_IFNAME': '^docker0'},\n",
       "   'Docker': {'BaseImage': 'mcr.microsoft.com/azureml/base-gpu:0.2.1',\n",
       "    'Enabled': True,\n",
       "    'SharedVolumes': True,\n",
       "    'Preparation': None,\n",
       "    'GpuSupport': True,\n",
       "    'ShmSize': '1g',\n",
       "    'Arguments': [],\n",
       "    'BaseImageRegistry': {'Address': None,\n",
       "     'Username': None,\n",
       "     'Password': None}},\n",
       "   'Spark': {'Repositories': ['https://mmlspark.azureedge.net/maven'],\n",
       "    'Packages': [{'Group': 'com.microsoft.ml.spark',\n",
       "      'Artifact': 'mmlspark_2.11',\n",
       "      'Version': '0.12'}],\n",
       "    'PrecachePackages': True}},\n",
       "  'History': {'OutputCollection': True},\n",
       "  'Spark': {'Configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'BatchAi': {'NodeCount': 0},\n",
       "  'AmlCompute': {'Name': None,\n",
       "   'VmSize': None,\n",
       "   'VmPriority': None,\n",
       "   'RetainCluster': False,\n",
       "   'ClusterMaxNodeCount': 1},\n",
       "  'Tensorflow': {'WorkerCount': 1, 'ParameterServerCount': 1},\n",
       "  'Mpi': {'ProcessCountPerNode': 1},\n",
       "  'Hdi': {'YarnDeployMode': 2},\n",
       "  'ContainerInstance': {'Region': None, 'CpuCores': 2, 'MemoryGb': 3.5},\n",
       "  'ExposedPorts': None,\n",
       "  'PrepareEnvironment': None},\n",
       " 'logFiles': {'azureml-logs/20_image_build_log.txt': 'https://zaml5744793264.blob.core.windows.net/azureml/ExperimentRun/dcid.keras-tf-exp-feb28_1551369917_43572d77/azureml-logs/20_image_build_log.txt?sv=2018-03-28&sr=b&sig=YzNyNw7bvkf60ra4QW6ZTwa9THTIRe0MVG3C11rcHug%3D&st=2019-02-28T16%3A15%3A49Z&se=2019-03-01T00%3A25%3A49Z&sp=r',\n",
       "  'azureml-logs/60_control_log.txt': 'https://zaml5744793264.blob.core.windows.net/azureml/ExperimentRun/dcid.keras-tf-exp-feb28_1551369917_43572d77/azureml-logs/60_control_log.txt?sv=2018-03-28&sr=b&sig=i%2BltwoQa27vLz8vPL9lrThP%2F78whh8O6pgGzpqncUH0%3D&st=2019-02-28T16%3A15%3A49Z&se=2019-03-01T00%3A25%3A49Z&sp=r',\n",
       "  'azureml-logs/80_driver_log.txt': 'https://zaml5744793264.blob.core.windows.net/azureml/ExperimentRun/dcid.keras-tf-exp-feb28_1551369917_43572d77/azureml-logs/80_driver_log.txt?sv=2018-03-28&sr=b&sig=Wdbb99Fcz2aJDmpNpIjA9sZ8nd%2FavJ%2FBh%2B0vwqYCGQQ%3D&st=2019-02-28T16%3A15%3A49Z&se=2019-03-01T00%3A25%3A49Z&sp=r',\n",
       "  'azureml-logs/azureml.log': 'https://zaml5744793264.blob.core.windows.net/azureml/ExperimentRun/dcid.keras-tf-exp-feb28_1551369917_43572d77/azureml-logs/azureml.log?sv=2018-03-28&sr=b&sig=Qh53wHxPq26sskGvn07IA0EIgKlT%2BSbHTourkbe%2F3Kg%3D&st=2019-02-28T16%3A15%3A49Z&se=2019-03-01T00%3A25%3A49Z&sp=r'}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.wait_for_completion(show_output=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
