{"cells":[{"cell_type":"code","source":["spark.conf.set(\n  \"fs.azure.account.key.zbatchaistorage.blob.core.windows.net\",\n  \"your_storage_key\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":1},{"cell_type":"code","source":["### mounting blob to databrick only once and it will be there forever \ndbutils.fs.mount(source = \"wasbs://mntdatabrick@zbatchaistorage.blob.core.windows.net/faces/\",mount_point = \"/mnt/root/\",extra_configs = {\"fs.azure.account.key.zbatchaistorage.blob.core.windows.net\": \"your_storage_access_key\"})"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["# read in csv file into spark:https://blog.arinti.be/databricks-importing-data-from-a-blob-storage-2b8dc700d029\ndf = spark.read.format(\"csv\").option(\"delimiter\",';').option(\"header\",\"true\").load(\"wasbs://mntdatabrick@zbatchaistorage.blob.core.windows.net/BreastCancerData.csv\", inferSchema = True)\ndf.show(3)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+---+---------+----------+---------+---------+---------+------+-----------+--------+\nClass|age|menopause|tumor-size|inv-nodes|node-caps|deg-malig|breast|breast-quad|irradiat|\n+-----+---+---------+----------+---------+---------+---------+------+-----------+--------+\n    0|  5|        1|         1|        1|        2|        1|     3|          1|       1|\n    0|  5|        4|         4|        5|        7|       10|     3|          2|       1|\n    0|  3|        1|         1|        1|        2|        2|     3|          1|       1|\n+-----+---+---------+----------+---------+---------+---------+------+-----------+--------+\nonly showing top 3 rows\n\n</div>"]}}],"execution_count":3},{"cell_type":"code","source":["data=df.select([\"age\", \"menopause\", \"tumor-size\", \"inv-nodes\",\"node-caps\",\"deg-malig\",\"breast\",\"breast-quad\",\"irradiat\",\"Class\"])\n\ntrain, test = data.randomSplit([0.75, 0.25], seed=123)\ntrain.toPandas()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">3</span><span class=\"ansired\">]: </span>\n     age  menopause  tumor-size  inv-nodes  node-caps  deg-malig  breast  \\\n0      1          1           1          1          1          1       1   \n1      1          1           1          1          1          1       1   \n2      1          1           1          1          1          1       2   \n3      1          1           1          1          1          1       2   \n4      1          1           1          1          1          1       2   \n5      1          1           1          1          1          1       2   \n6      1          1           1          1          1          1       3   \n7      1          1           1          1          1          1       3   \n8      1          1           1          1          1          1       3   \n9      1          1           1          1          1          1       3   \n10     1          1           1          1          1          1       3   \n11     1          1           1          1          2          1       1   \n12     1          1           1          1          2          1       1   \n13     1          1           1          1          2          1       1   \n14     1          1           1          1          2          1       1   \n15     1          1           1          1          2          1       1   \n16     1          1           1          1          2          1       1   \n17     1          1           1          1          2          1       1   \n18     1          1           1          1          2          1       1   \n19     1          1           1          1          2          1       1   \n20     1          1           1          1          2          1       1   \n21     1          1           1          1          2          1       1   \n22     1          1           1          1          2          1       1   \n23     1          1           1          1          2          1       1   \n24     1          1           1          1          2          1       1   \n25     1          1           1          1          2          1       1   \n26     1          1           1          1          2          1       1   \n27     1          1           1          1          2          1       1   \n28     1          1           1          1          2          1       1   \n29     1          1           1          1          2          1       1   \n..   ...        ...         ...        ...        ...        ...     ...   \n478   10          6           6          3          4          5       3   \n479   10          7           7          3          8          5       7   \n480   10          7           7          4          5         10       5   \n481   10          8           4          4          4         10       3   \n482   10          8           7          4          3         10       7   \n483   10          8           8          2          3          4       8   \n484   10          8           8          2          8         10       4   \n485   10          8           8          4         10         10       8   \n486   10          8          10         10          6          1       3   \n487   10          9           7          3          4          2       7   \n488   10          9           8          7          6          4       7   \n489   10         10           6          3          3         10       4   \n490   10         10           7          8          7          1      10   \n491   10         10           8          6          4          5       8   \n492   10         10           8         10          6          5      10   \n493   10         10           9          3          7          5       3   \n494   10         10          10          2         10         10       5   \n495   10         10          10          3         10          8       8   \n496   10         10          10          3         10         10       9   \n497   10         10          10          4          8          1       8   \n498   10         10          10          6          8          4       8   \n499   10         10          10          7          9         10       7   \n500   10         10          10          8          2         10       4   \n501   10         10          10          8          6          1       8   \n502   10         10          10          8          6          8       7   \n503   10         10          10         10          3         10      10   \n504   10         10          10         10          5         10      10   \n505   10         10          10         10          6         10       8   \n506   10         10          10         10          7         10       7   \n507   10         10          10         10         10          1       8   \n\n     breast-quad  irradiat  Class  \n0              1         1      0  \n1              3         1      0  \n2              1         1      0  \n3              1         1      0  \n4              1         1      0  \n5              1         1      0  \n6              1         1      0  \n7              1         1      0  \n8              1         1      0  \n9              1         1      0  \n10             1         1      0  \n11             1         1      0  \n12             1         1      0  \n13             1         1      0  \n14             1         1      0  \n15             1         1      0  \n16             1         1      0  \n17             1         1      0  \n18             1         1      0  \n19             1         1      0  \n20             1         1      0  \n21             1         1      0  \n22             1         1      0  \n23             1         1      0  \n24             1         1      0  \n25             1         1      0  \n26             1         1      0  \n27             1         1      0  \n28             1         1      0  \n29             1         1      0  \n..           ...       ...    ...  \n478            6         1      1  \n479            4         3      1  \n480            7         2      1  \n481           10         4      1  \n482            9         1      1  \n483            7         8      1  \n484            8        10      1  \n485            1         1      1  \n486            1        10      1  \n487            7         1      1  \n488           10         3      1  \n489            3         2      1  \n490           10         3      1  \n491           10         1      1  \n492            3         1      1  \n493            5         1      1  \n494            3         3      1  \n495            1         1      1  \n496           10         1      1  \n497           10         1      1  \n498            5         1      1  \n499           10        10      1  \n500            1         1      1  \n501            9         1      1  \n502           10         1      1  \n503            6         1      1  \n504           10         7      1  \n505            1         5      1  \n506           10         4      1  \n507            8         8      1  \n\n[508 rows x 10 columns]\n</div>"]}}],"execution_count":4},{"cell_type":"code","source":["from mmlspark import TuneHyperparameters\nfrom mmlspark.TrainClassifier import TrainClassifier\nfrom pyspark.ml.classification import LogisticRegression, RandomForestClassifier, GBTClassifier\nlogReg = LogisticRegression()\nrandForest = RandomForestClassifier()\ngbt = GBTClassifier()\nsmlmodels = [logReg, randForest, gbt]\nmmlmodels = [TrainClassifier(model=model, labelCol=\"Class\") for model in smlmodels]"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"code","source":["from mmlspark import HyperparamBuilder\nfrom mmlspark import RangeHyperParam\nfrom mmlspark import DiscreteHyperParam\nfrom mmlspark import RandomSpace\nparamBuilder = \\\n  HyperparamBuilder() \\\n    .addHyperparam(logReg, logReg.regParam, RangeHyperParam(0.1, 0.3, isDouble=True)) \\\n    .addHyperparam(randForest, randForest.numTrees, DiscreteHyperParam([5,10])) \\\n    .addHyperparam(randForest, randForest.maxDepth, DiscreteHyperParam([3,5])) \\\n    .addHyperparam(gbt, gbt.maxBins, RangeHyperParam(8,16)) \\\n    .addHyperparam(gbt, gbt.maxDepth, DiscreteHyperParam([3,5]))\nrandomSpace = RandomSpace(paramBuilder.build())"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":6},{"cell_type":"code","source":["bestModel = TuneHyperparameters(\n              evaluationMetric=\"accuracy\", models=mmlmodels, numFolds=2,\n              numRuns=len(mmlmodels) * 2, parallelism=1,\n              paramSpace=randomSpace.space(), seed=0).fit(train)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":7},{"cell_type":"code","source":["from mmlspark import ComputeModelStatistics\nprediction = bestModel.transform(test)\nmetrics = ComputeModelStatistics().transform(prediction)\nm=metrics.toPandas()\nm"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">7</span><span class=\"ansired\">]: </span>\n  evaluation_type                                   confusion_matrix  \\\n0  Classification  DenseMatrix([[ 108.,    4.],\\n             [  ...   \n\n   accuracy  precision    recall       AUC  \n0  0.954286   0.936508  0.936508  0.979238  \n</div>"]}}],"execution_count":8},{"cell_type":"code","source":["### operationalize the model for an api call\nfrom pyspark.sql.functions import col, from_json\nfrom pyspark.sql.types import *\nimport uuid\n\nserving_inputs = spark.readStream.server() \\\n    .address(\"localhost\", 8898, \"my_api\") \\\n    .load()\\\n    .withColumn(\"variables\", from_json(col(\"value\"), test.schema))\\\n    .select(\"id\",\"variables.*\")\n\nserving_outputs = bestModel.transform(serving_inputs) \\\n  .withColumn(\"scored_labels\", col(\"scored_labels\").cast(\"string\"))\n\nserver = serving_outputs.writeStream \\\n    .server() \\\n    .option(\"name\", \"my_api\") \\\n    .queryName(\"my_query\") \\\n    .option(\"replyCol\", \"scored_labels\") \\\n    .option(\"checkpointLocation\", \"checkpoints-{}\".format(uuid.uuid1())) \\\n    .start()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":9},{"cell_type":"code","source":["df.show(1)\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+---+---------+----------+---------+---------+---------+------+-----------+--------+\nClass|age|menopause|tumor-size|inv-nodes|node-caps|deg-malig|breast|breast-quad|irradiat|\n+-----+---+---------+----------+---------+---------+---------+------+-----------+--------+\n    0|  5|        1|         1|        1|        2|        1|     3|          1|       1|\n+-----+---+---------+----------+---------+---------+---------+------+-----------+--------+\nonly showing top 1 row\n\n</div>"]}}],"execution_count":10},{"cell_type":"code","source":["serving_inputs"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">9</span><span class=\"ansired\">]: </span>DataFrame[id: bigint, age: int, menopause: int, tumor-size: int, inv-nodes: int, node-caps: int, deg-malig: int, breast: int, breast-quad: int, irradiat: int, Class: int]\n</div>"]}}],"execution_count":11},{"cell_type":"code","source":["import requests\ndat = u'{\"age\":5,\"menopause\":1,\"tumor-size\":1,\"inv-nodes\":1,\"node-caps\":2,\"deg-malig\":1,\"breast\":3,\"breast-quad\":1,\"irradiat\":1,\"Class\":0}'\nr = requests.post(data=dat, url=\"http://localhost:8898/my_api\")\nprint(\"Response {}\".format(r.text))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Response 0.0\n</div>"]}}],"execution_count":12},{"cell_type":"code","source":["import mmlspark\nimport numpy as np\nfrom mmlspark import toNDArray\n\nfemaleimageDir = \"wasbs://mntdatabrick@zbatchaistorage.blob.core.windows.net/faces/female\"\nfimages = spark.readImages(femaleimageDir, recursive = True, sampleRatio = 0.1).cache()\n\nmaleimageDir = \"wasbs://mntdatabrick@zbatchaistorage.blob.core.windows.net/faces/female\"\nmimages = spark.readImages(femaleimageDir, recursive = True, sampleRatio = 0.1).cache()\nmimages.printSchema()\nprint(fimages.count(), mimages.count())"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- image: struct (nullable = true)\n    |-- path: string (nullable = true)\n    |-- height: integer (nullable = true)\n    |-- width: integer (nullable = true)\n    |-- type: integer (nullable = true)\n    |-- bytes: binary (nullable = true)\n\n10 10\n</div>"]}}],"execution_count":13}],"metadata":{"name":"read_from_Blob","notebookId":1277953500304263},"nbformat":4,"nbformat_minor":0}
