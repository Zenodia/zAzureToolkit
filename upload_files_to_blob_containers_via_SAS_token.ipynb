{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\" for further reading refer to the urls below \n",
    "simple one: https://docs.microsoft.com/en-us/azure/storage/blobs/storage-quickstart-blobs-python\n",
    "advanced : https://github.com/Azure-Samples/storage-blob-python-getting-started/blob/master/blob_advanced_samples.py\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "import os, uuid, sys\n",
    "from azure.storage.blob import BlockBlobService, PublicAccess\n",
    "\n",
    "from __future__ import print_function\n",
    "import datetime\n",
    "import io\n",
    "import time\n",
    "\n",
    "\n",
    "import azure.storage.blob as azureblob\n",
    "import azure.batch.batch_service_client as batch\n",
    "import azure.batch.batch_auth as batchauth\n",
    "\n",
    "from azure.storage.blob import (\n",
    "    BlockBlobService,\n",
    "    BlobPermissions\n",
    ")\n",
    "from azure.storage.blob import (\n",
    "    ContentSettings,\n",
    "    BlobBlock,\n",
    "    BlockListType,\n",
    ")\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from azure.storage.blob import (\n",
    "    BlockBlobService,\n",
    "    ContainerPermissions,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n### to not share your keys visuable in the notebook, protect your keys by constructing your own json keys save document\\n### only use the below to construct your own keys document for the first time, uncomment to use\\nimport json\\n\\ndata = {}  \\ndata[\\'keys\\'] = []  \\ndata[\\'keys\\'].append({  \\n    \"_STORAGE_ACCOUNT_KEY\": <your_azure_storage_key>\\',\\n    \"_STORAGE_ACCOUNT_NAME\": <the_storage_acc_name>,\\n    \"containerName\": <the_container_name>\\n})\\nprint(data)\\nwith open(\\'storage.txt\\', \\'w\\') as outfile:  \\n    json.dump(data, outfile)\\n    '"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "### to not share your keys visuable in the notebook, protect your keys by constructing your own json keys save document\n",
    "### only use the below to construct your own keys document for the first time, uncomment to use\n",
    "import json\n",
    "\n",
    "data = {}  \n",
    "data['keys'] = []  \n",
    "data['keys'].append({  \n",
    "    \"_STORAGE_ACCOUNT_KEY\": <your_azure_storage_key>',\n",
    "    \"_STORAGE_ACCOUNT_NAME\": <the_storage_acc_name>,\n",
    "    \"containerName\": <the_container_name>\n",
    "})\n",
    "print(data)\n",
    "with open('storage.txt', 'w') as outfile:  \n",
    "    json.dump(data, outfile)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'pythonin'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "with open('storage.txt') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "\n",
    "pprint(data['keys'][0]['containerName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pythonin', 'pythonout']\n"
     ]
    }
   ],
   "source": [
    "# Create the blob client, for use in obtaining references to\n",
    "# blob storage containers and uploading files to containers.\n",
    "_STORAGE_ACCOUNT_NAME=data['keys'][0]['_STORAGE_ACCOUNT_NAME']\n",
    "_STORAGE_ACCOUNT_KEY=data['keys'][0]['_STORAGE_ACCOUNT_KEY']\n",
    "containerName=data['keys'][0]['containerName'] # the container name you are interested in\n",
    "\n",
    "### this is where you create the connection by supplying azureblob.BlockBlobService ( acc_name , acc_key)\n",
    "\n",
    "blob_client = azureblob.BlockBlobService(\n",
    "    account_name=_STORAGE_ACCOUNT_NAME,\n",
    "    account_key=_STORAGE_ACCOUNT_KEY)\n",
    "# check the connection is established by list the name of the container in the blob storage\n",
    "print([blob.name for blob in blob_client.list_containers() ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pythonin', 'pythonout']\n"
     ]
    }
   ],
   "source": [
    "##### create containers \n",
    "input_container_name = 'pythonin'\n",
    "output_container_name = 'pythonout'\n",
    "blob_client.create_container(input_container_name, fail_on_exist=False)\n",
    "blob_client.create_container(output_container_name, fail_on_exist=False)\n",
    "print([blob.name for blob in blob_client.list_containers() ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get sas token and url\n",
    "def get_container_sas_token(block_blob_client,\n",
    "                            container_name, blob_permissions):\n",
    "    \"\"\"\n",
    "    Obtains a shared access signature granting the specified permissions to the\n",
    "    container.\n",
    "\n",
    "    :param block_blob_client: A blob service client.\n",
    "    :type block_blob_client: `azure.storage.blob.BlockBlobService`\n",
    "    :param str container_name: The name of the Azure Blob storage container.\n",
    "    :param BlobPermissions blob_permissions:\n",
    "    :rtype: str\n",
    "    :return: A SAS token granting the specified permissions to the container.\n",
    "    \"\"\"\n",
    "    # Obtain the SAS token for the container, setting the expiry time and\n",
    "    # permissions. In this case, no start time is specified, so the shared\n",
    "    # access signature becomes valid immediately. Expiration is in 2 hours.\n",
    "    container_sas_token = \\\n",
    "        block_blob_client.generate_container_shared_access_signature(\n",
    "            container_name,\n",
    "            permission=blob_permissions,\n",
    "            expiry=datetime.utcnow() + timedelta(hours=2))\n",
    "       \n",
    "\n",
    "    return container_sas_token\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_container_sas_url(block_blob_client,\n",
    "                            container_name, blob_permissions):\n",
    "    \"\"\"\n",
    "    Obtains a shared access signature URL that provides write access to the \n",
    "    ouput container to which the tasks will upload their output.\n",
    "\n",
    "    :param block_blob_client: A blob service client.\n",
    "    :type block_blob_client: `azure.storage.blob.BlockBlobService`\n",
    "    :param str container_name: The name of the Azure Blob storage container.\n",
    "    :param BlobPermissions blob_permissions:\n",
    "    :rtype: str\n",
    "    :return: A SAS URL granting the specified permissions to the container.\n",
    "    \"\"\"\n",
    "    # Obtain the SAS token for the container.\n",
    "    sas_token = get_container_sas_token(block_blob_client,\n",
    "                            container_name, azureblob.BlobPermissions.WRITE)\n",
    "\n",
    "    # Construct SAS URL for the container\n",
    "    container_sas_url = \"https://{}.blob.core.windows.net/{}?{}\".format(_STORAGE_ACCOUNT_NAME, container_name, sas_token)\n",
    "\n",
    "    return container_sas_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://bl*****\n"
     ]
    }
   ],
   "source": [
    "### this is how to use get_container_sas_url function above by manipulating policy used \n",
    "policy=azureblob.BlobPermissions.READ+azureblob.BlobPermissions.READ\n",
    "su=get_container_sas_url(blob_client,input_container_name, policy )\n",
    "print(su[:10]+'*****')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def properties_and_metadata_operations(create_container_name,account, local_file_path, deletYN):\n",
    "\n",
    "        file_blob_name = \"tinycat.png\"\n",
    "\n",
    "        text_blob_name = \"Text\"\n",
    "\n",
    "         \n",
    "\n",
    "        # Create a Block Blob Service object\n",
    "\n",
    "        #blockblob_service = account.create_block_blob_service()\n",
    "\n",
    "\n",
    "\n",
    "        container_name = create_container_name\n",
    "\n",
    "\n",
    "\n",
    "        try:\n",
    "\n",
    "            # Create a new container\n",
    "\n",
    "            print('1. Create a container with name and custom metadata - ' + container_name)\n",
    "\n",
    "            account.create_container(container_name, {'sample':'azure-storage'})\n",
    "\n",
    "                    \n",
    "\n",
    "            # Upload file as a block blob\n",
    "\n",
    "            print('2. Uploading BlockBlob from file with properties and custom metadata')\n",
    "\n",
    "            #Get full path on drive to file_to_upload by joining the fully qualified directory name and file name on the local drive\n",
    "\n",
    "            full_path_to_file = os.path.join(local_file_path, file_blob_name)\n",
    "\n",
    "            \n",
    "\n",
    "            account.create_blob_from_path(container_name, file_blob_name, full_path_to_file, \n",
    "\n",
    "                content_settings=ContentSettings(content_type='application/png'),\n",
    "\n",
    "                metadata={'category':'azure-samples'})\n",
    "\n",
    "            \n",
    "\n",
    "            account.create_blob_from_text(container_name, text_blob_name, 'Data',\n",
    "\n",
    "                content_settings=ContentSettings(content_encoding ='UTF-8', content_language='en'),\n",
    "\n",
    "                metadata={'origin':'usa', 'title': 'azure-samples'})\n",
    "\n",
    "            \n",
    "\n",
    "            # Get all the container properties \n",
    "\n",
    "            print('3. Get Container metadata')\n",
    "\n",
    "\n",
    "\n",
    "            container = account.get_container_properties(container_name)\n",
    "\n",
    "            \n",
    "\n",
    "            print('    Metadata:')\n",
    "\n",
    "\n",
    "\n",
    "            for key in container.metadata:\n",
    "\n",
    "                print('        ' + key + ':' + container.metadata[key])\n",
    "\n",
    "            \n",
    "\n",
    "            # Get all the blob properties \n",
    "\n",
    "            print('4. Get Blob properties')\n",
    "\n",
    "            blob = account.get_blob_properties(container_name, file_blob_name)\n",
    "\n",
    "            \n",
    "\n",
    "            print('    Metadata:')\n",
    "\n",
    "            for key in blob.metadata:\n",
    "\n",
    "                print('        ' + key + ':' + blob.metadata[key])\n",
    "\n",
    "            \n",
    "\n",
    "            print('    Properties:')\n",
    "\n",
    "            print('        Content-Type:' + blob.properties.content_settings.content_type)\n",
    "\n",
    "        finally:            \n",
    "\n",
    "            # Delete the container\n",
    "\n",
    "            print(\"5. Delete Container :\", str(deletYN))\n",
    "\n",
    "            if account.exists(container_name) and (deletYN):\n",
    "\n",
    "                account.delete_container(container_name)\n",
    "                print(\"container :{} deleted\".format(container_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Create a container with name and custom metadata - testpropmeta\n",
      "2. Uploading BlockBlob from file with properties and custom metadata\n",
      "3. Get Container metadata\n",
      "    Metadata:\n",
      "        sample:azure-storage\n",
      "4. Get Blob properties\n",
      "    Metadata:\n",
      "        category:azure-samples\n",
      "    Properties:\n",
      "        Content-Type:application/png\n",
      "5. Delete Container : True\n",
      "container :testpropmeta deleted\n",
      "double check it is deleted in azure\n",
      "['pythonin', 'pythonout']\n"
     ]
    }
   ],
   "source": [
    "local_path=os.path.expanduser(\"~/Desktop/zeno_azure_toolkit/\")\n",
    "properties_and_metadata_operations('testpropmeta',blob_client,local_path, True)\n",
    "print(\"double check it is deleted in azure\")\n",
    "print([blob.name for blob in blob_client.list_containers() ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### upload files from local PC up to blob \n",
    "def upload_file_to_container(block_blob_client, container_name, file_path):\n",
    "    \"\"\"\n",
    "    Uploads a local file to an Azure Blob storage container.\n",
    "\n",
    "    :param block_blob_client: A blob service client.\n",
    "    :type block_blob_client: `azure.storage.blob.BlockBlobService`\n",
    "    :param str container_name: The name of the Azure Blob storage container.\n",
    "    :param str file_path: The local path to the file.\n",
    "    :rtype: `azure.batch.models.ResourceFile`\n",
    "    :return: A ResourceFile initialized with a SAS URL appropriate for Batch\n",
    "    tasks.\n",
    "    \"\"\"\n",
    "    blob_name = os.path.basename(file_path)\n",
    "\n",
    "    print('Uploading file {} to container [{}]...'.format(file_path,\n",
    "                                                          container_name))\n",
    "\n",
    "    block_blob_client.create_blob_from_path(container_name,\n",
    "                                            blob_name,\n",
    "                                            file_path)\n",
    "    \n",
    "    # Obtain the SAS token for the container.\n",
    "    sas_token = get_container_sas_token(block_blob_client,\n",
    "                            container_name, azureblob.BlobPermissions.READ+azureblob.BlobPermissions.READ)\n",
    "    # syntax ContainerPermissions(read=False, write=False, delete=False, list=False, _str=None)\n",
    "    \n",
    "    \n",
    "\n",
    "    sas_url = block_blob_client.make_blob_url(container_name,\n",
    "                                              blob_name,\n",
    "                                              sas_token=sas_token)\n",
    "\n",
    "    return blob_name, sas_token,sas_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-09 11:30:56.194182\n",
      "2 days, 0:00:00\n"
     ]
    }
   ],
   "source": [
    "print(datetime.utcnow())\n",
    "print(timedelta(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading file C:\\Users\\zecharpy\\Desktop\\batch-python-ffmpeg-tutorial\\src\\InputFiles\\LowPriVMs-1.mp4 to container [pythonin]...\n",
      "Uploading file C:\\Users\\zecharpy\\Desktop\\batch-python-ffmpeg-tutorial\\src\\InputFiles\\LowPriVMs-2.mp4 to container [pythonin]...\n",
      "Uploading file C:\\Users\\zecharpy\\Desktop\\batch-python-ffmpeg-tutorial\\src\\InputFiles\\LowPriVMs-3.mp4 to container [pythonin]...\n",
      "Uploading file C:\\Users\\zecharpy\\Desktop\\batch-python-ffmpeg-tutorial\\src\\InputFiles\\LowPriVMs-4.mp4 to container [pythonin]...\n",
      "Uploading file C:\\Users\\zecharpy\\Desktop\\batch-python-ffmpeg-tutorial\\src\\InputFiles\\LowPriVMs-5.mp4 to container [pythonin]...\n",
      "['LowPriVMs-1.mp4', 'LowPriVMs-2.mp4', 'LowPriVMs-3.mp4', 'LowPriVMs-4.mp4', 'LowPriVMs-5.mp4']\n"
     ]
    }
   ],
   "source": [
    "#### let's actually upload some files to the blob in the pythonin container  created above \n",
    "local_path=os.path.expanduser(\"~/Desktop/batch-python-ffmpeg-tutorial/src/\")\n",
    "#print([fil for fil in os.listdir(local_path+'InputFiles')])\n",
    "\n",
    "\n",
    "input_file_paths = []\n",
    "        \n",
    "for folder, subs, files in os.walk(local_path+'InputFiles/'):\n",
    "    for filename in files:\n",
    "        if filename.endswith(\".mp4\"):\n",
    "            input_file_paths.append(os.path.abspath(os.path.join(folder, filename)))\n",
    "\n",
    "            \n",
    "# Upload the input files. This is the collection of files that are to be processed by the tasks. \n",
    "uploaded_file_tokens={}\n",
    "for file_path in input_file_paths:\n",
    "    \n",
    "    #if file_path.endswith('1.mp4'):\n",
    "        #print(file_path)\n",
    "    bn,sast,sasu=upload_file_to_container(blob_client, input_container_name, file_path)\n",
    "    #print(\"bn\",bn)\n",
    "    #print(\"sastoken\", sast)\n",
    "    #print(\"sas url\", sasu)\n",
    "    uploaded_file_tokens[bn]=[sast,sasu]\n",
    "        \n",
    "#input_files = [\n",
    "#    upload_file_to_container(blob_client, input_container_name, file_path)\n",
    "#    for file_path in input_file_paths]\n",
    "\n",
    "\n",
    "### check the files are uploaded sucessfully \n",
    "print([blob.name for blob in blob_client.list_blobs(input_container_name)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('LowPriVMs-1.mp4',\n",
       " '',\n",
       " ['.ipynb_checkpoints',\n",
       "  '3.jpg',\n",
       "  'azureblob4python.yml',\n",
       "  'azure_ComputerVision_pythonAPI.ipynb',\n",
       "  'handwritter_test.jpg',\n",
       "  'resize.jpg',\n",
       "  'storage.txt',\n",
       "  'tinycat.PNG',\n",
       "  'upload_files_to_blob_containers_via_SAS_token.ipynb',\n",
       "  'video.jpg'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(uploaded_file_tokens.keys())[0], os.path.dirname('LowPriVMs-1.mp4'), os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confirmed file :LowPriVMs-1.mp4.copy.mp4 in directory :C:\\Users\\zecharpy/Desktop/batch-python-ffmpeg-tutorial/src/ is found\n"
     ]
    }
   ],
   "source": [
    "# read this below\n",
    "#https://github.com/Azure-Samples/storage-blob-python-getting-started/blob/master/blob_advanced_samples.py\n",
    "#### this is how you download files=blobs from a container \n",
    "\n",
    "blob_client.get_blob_to_path(input_container_name, 'LowPriVMs-1.mp4', os.path.join(local_path,'LowPriVMs-1.mp4'  + '.copy.mp4'))\n",
    "#####confirm the file with .copy as extension is indeed there \n",
    "for f in os.listdir(local_path):\n",
    "    if f.endswith('.copy.mp4'):\n",
    "        print(\"confirmed file :{} in directory :{} is found\".format(f, local_path))\n",
    "        ## comment out os.remove if you want to keep the files downloaded from  the blob\n",
    "        os.remove(local_path+f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### copying from one container to another\n",
    "\n",
    "def copy_blob(blob_service,copy_from_container, copy_to_container, blobname_to_copy, deletOldYN):\n",
    "    blob_service.create_container(copy_to_container, fail_on_exist=False)\n",
    "    blob_url = blob_service.make_blob_url(copy_from_container,blobname_to_copy)\n",
    "    # blob_url:https://demostorage.blob.core.windows.net/image-container/pretty.jpg\n",
    "\n",
    "    blob_service.copy_blob(copy_to_container, blobname_to_copy, blob_url)\n",
    "\n",
    "    if deletOldYN:\n",
    "        #for move the file use this line\n",
    "        blob_service.delete_blob(copy_from_container, blob_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['copypythonin', 'pythonin', 'pythonout']\n",
      "clean up by deleting the extra container we created for copying  copypythonin\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "copy_blob(blob_client, 'pythonin','copypythonin','LowPriVMs-1.mp4',False)\n",
    "\n",
    "print([container.name for container in blob_client.list_containers()])\n",
    "### clean up by deleting the extra container \n",
    "print(\"clean up by deleting the extra container we created for copying \", 'copypythonin')\n",
    "print(blob_client.delete_container('copypythonin'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
